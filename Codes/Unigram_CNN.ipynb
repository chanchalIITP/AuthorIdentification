{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Unigram_CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U7M6zRCxQLU"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhwU6GgVQmuw",
        "outputId": "acd1261b-cf5f-45cd-e1eb-1ee1d5b6cbc1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFru4OXiyUu2"
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(0)\n",
        "import numpy as np\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Model\n",
        "import os\n",
        "import math\n",
        "from termcolor import colored\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import pandas as pd\n",
        "#from data_helpers import load_data\n",
        "from keras import callbacks\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#from keras.utils.vis_utils import plot_model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.callbacks import TensorBoard\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Input, Dense, Dropout, Flatten\n",
        "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdrvi3HJW-zI"
      },
      "source": [
        "dataset=pd.read_csv('/content/drive/MyDrive/1000_tweets_per_user_train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgER-ZW-XQJU"
      },
      "source": [
        "k=0\n",
        "X_train=[]\n",
        "y_train=[]\n",
        "for i in range(0,50):\n",
        "  for j in range(k,k+45):\n",
        "    X_train.append(dataset.iloc[j,0])\n",
        "    y_train.append(dataset.iloc[j,1])\n",
        "  k+=60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBtRpMhYXQN8"
      },
      "source": [
        "k=45\n",
        "X_test=[]\n",
        "y_test=[]\n",
        "for i in range(0,50):\n",
        "  for j in range(k,k+5):\n",
        "    X_test.append(dataset.iloc[j,0])\n",
        "    y_test.append(dataset.iloc[j,1])\n",
        "  k+=60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pKyP0O7XQVh"
      },
      "source": [
        "X_train=pd.DataFrame(X_train)\n",
        "X_test=pd.DataFrame(X_test)\n",
        "y_train=pd.DataFrame(y_train)\n",
        "y_test=pd.DataFrame(y_test)\n",
        "X_train=X_train.iloc[:,:].values\n",
        "X_test=X_test.iloc[:,:].values\n",
        "y_train=y_train.iloc[:,:].values\n",
        "y_test=y_test.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-T84F3U8XQdd"
      },
      "source": [
        "train=np.concatenate((X_train,y_train),axis=1)\n",
        "test=np.concatenate((X_test,y_test),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBzSD-8MXQbb"
      },
      "source": [
        "np.random.shuffle(train)\n",
        "np.random.shuffle(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1--atJbEXQY5"
      },
      "source": [
        "train=pd.DataFrame(train)\n",
        "test=pd.DataFrame(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "KT0lRZvPXQTe",
        "outputId": "a887c6a5-2a6a-48a1-d094-da1bd71c6c01"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "id": "XqiBcUfJXQRC",
        "outputId": "cd7b40f3-ce99-4527-edf8-7dfb2e95bb2f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEz-UOEDX6By"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer() \n",
        "\n",
        "def preprocess(sentence):\n",
        "  sentence=str(sentence)\n",
        "  sentence = sentence.lower()\n",
        "  sentence=sentence.replace('{html}',\"\") \n",
        "  cleanr = re.compile('<.*?>#@')\n",
        "  cleantext = re.sub(cleanr, '', sentence)\n",
        "  rem_url=re.sub(r'http\\S+', '',cleantext)\n",
        "  rem_num = re.sub('[0-9]+', '', rem_url)\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(rem_num)  \n",
        "  filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "  stem_words=[stemmer.stem(w) for w in filtered_words]\n",
        "  lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
        "  return \" \".join(filtered_words)\n",
        "\n",
        "\n",
        "train.iloc[:,0]=train.iloc[:,0].map(lambda s:preprocess(s))\n",
        "test.iloc[:,0]=test.iloc[:,0].map(lambda s:preprocess(s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1Linya6X91_"
      },
      "source": [
        "X_train=train.iloc[:,0]\n",
        "X_test=test.iloc[:,0]\n",
        "y_train=train.iloc[:,1]\n",
        "y_test=test.iloc[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOk6opokYA2D"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_train)\n",
        "encoded_Y = encoder.transform(y_train)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "y_train = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAtF4g5tYCh6"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_test)\n",
        "encoded_Y = encoder.transform(y_test)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "y_test = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMFxE1yjYdHy"
      },
      "source": [
        "def create_vocab_set():\n",
        "    alphabet = (list(string.ascii_lowercase) + list(string.digits) +\n",
        "                list(string.punctuation) + ['\\n'] + [' '] )\n",
        "    vocab_size = len(alphabet)\n",
        "    check = set(alphabet)\n",
        "\n",
        "    vocab = {}\n",
        "    reverse_vocab = {}\n",
        "    for ix, t in enumerate(alphabet):\n",
        "        vocab[t] = ix\n",
        "        reverse_vocab[ix] = t\n",
        "\n",
        "    return vocab, reverse_vocab, vocab_size, check"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUlQkSTMYGW-"
      },
      "source": [
        "maxlen = 50\n",
        "vocab, reverse_vocab, vocab_size, check = create_vocab_set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_NU17VPYfO-"
      },
      "source": [
        "def encode_data(x, maxlen, vocab, vocab_size, check):\n",
        "\n",
        "    input_data = np.zeros((len(x), maxlen, vocab_size))\n",
        "    for dix, sent in enumerate(x):\n",
        "        counter = 0\n",
        "        sent_array = np.zeros((maxlen, vocab_size))\n",
        "        chars = list(sent.lower())\n",
        "        for c in chars:\n",
        "            if counter >= maxlen:\n",
        "                pass\n",
        "            else:\n",
        "                char_array = np.zeros(vocab_size, dtype=np.int)\n",
        "                if c in check:\n",
        "                    ix = vocab[c]\n",
        "                    char_array[ix] = 1\n",
        "                sent_array[counter, :] = char_array\n",
        "                counter += 1\n",
        "        input_data[dix, :, :] = sent_array\n",
        "\n",
        "    return input_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk2mCFkFZKPx"
      },
      "source": [
        "X_train = encode_data(X_train, maxlen, vocab, vocab_size, check)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fKuVJcCZPNE"
      },
      "source": [
        "X_test = encode_data(X_test, maxlen, vocab, vocab_size, check)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AImh1d-bEIu"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(X_train,y_train, test_size = 0.05, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6T7surlbNUl"
      },
      "source": [
        "def model(filter_kernels, dense_outputs, maxlen, vocab_size, nb_filter,\n",
        "          cat_output):\n",
        "    inputs = Input(shape=(maxlen, vocab_size), name='input', dtype='float32')\n",
        "\n",
        "    conv = Convolution1D(nb_filter=nb_filter, filter_length=filter_kernels[0],\n",
        "                         border_mode='valid', activation='relu',\n",
        "                         input_shape=(maxlen, vocab_size))(inputs)\n",
        "    conv = MaxPooling1D(pool_length=3)(conv)\n",
        "\n",
        "    conv1 = Convolution1D(nb_filter=nb_filter, filter_length=filter_kernels[1],\n",
        "                          border_mode='valid', activation='relu')(conv)\n",
        "    conv1 = MaxPooling1D(pool_length=3)(conv1)\n",
        "\n",
        "    conv2 = Convolution1D(nb_filter=nb_filter, filter_length=filter_kernels[2],\n",
        "                          border_mode='valid', activation='relu')(conv1)\n",
        "\n",
        "    # conv3 = Convolution1D(nb_filter=nb_filter, filter_length=filter_kernels[3],\n",
        "    #                       border_mode='valid', activation='relu')(conv2)\n",
        "\n",
        "    # conv4 = Convolution1D(nb_filter=nb_filter, filter_length=filter_kernels[4],\n",
        "    #                       border_mode='valid', activation='relu')(conv3)\n",
        "\n",
        "    # conv5 = Convolution1D(nb_filter=nb_filter, filter_length=filter_kernels[5],---------\n",
        "    #                       border_mode='valid', activation='relu')(conv4)\n",
        "    # conv5 = MaxPooling1D(pool_length=3)(conv5)\n",
        "    conv5 = Flatten()(conv2)\n",
        "\n",
        "    #Two dense layers with dropout of .5\n",
        "    z = Dropout(0.5)(Dense(dense_outputs, activation='relu')(conv5))\n",
        "    # z = Dropout(0.5)(Dense(dense_outputs, activation='relu')(z))\n",
        "\n",
        "    pred = Dense(cat_output, activation='softmax', name='output')(z)\n",
        "\n",
        "    model = Model(input=inputs, output=pred)\n",
        "\n",
        "    sgd = SGD(lr=0.01, momentum=0.9)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "vyttKXDhbImp",
        "outputId": "1a74854b-a8b7-4139-ddc1-e5b42dfd2187"
      },
      "source": [
        "    nb_filter = 450\n",
        "    dense_outputs = 256\n",
        "    filter_kernels = [1, 2, 3]\n",
        "    cat_output = 50\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "    model = model(filter_kernels, dense_outputs, 50, vocab_size, nb_filter, cat_output)\n",
        "    model.summary()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           (None, 50, 70)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 50, 450)           31950     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 16, 450)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 15, 450)           405450    \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 5, 450)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 3, 450)            607950    \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 1350)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               345856    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 50)                12850     \n",
            "=================================================================\n",
            "Total params: 1,404,056\n",
            "Trainable params: 1,404,056\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", input_shape=(50, 70), filters=450, kernel_size=1, padding=\"valid\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=3)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=450, kernel_size=2, padding=\"valid\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=3)`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=450, kernel_size=3, padding=\"valid\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ou...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtWtAFFzbj_o"
      },
      "source": [
        "    Adam(lr=1.00, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "x8-RPTp-lYqM",
        "outputId": "09e78978-516b-4a50-b9cd-087ba1aa00b3"
      },
      "source": [
        "model.fit(np.array(X_train), np.array(y_train), validation_data=[np.array(X_eval), np.array(y_eval)],batch_size=32,epochs=15, verbose=1, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2137 samples, validate on 113 samples\n",
            "Epoch 1/15\n",
            "2137/2137 [==============================] - 1s 364us/step - loss: 3.9224 - accuracy: 0.0159 - val_loss: 3.9140 - val_accuracy: 0.0088\n",
            "Epoch 2/15\n",
            "2137/2137 [==============================] - 0s 185us/step - loss: 3.9135 - accuracy: 0.0225 - val_loss: 3.9139 - val_accuracy: 0.0177\n",
            "Epoch 3/15\n",
            "2137/2137 [==============================] - 0s 192us/step - loss: 3.9062 - accuracy: 0.0262 - val_loss: 3.9029 - val_accuracy: 0.0265\n",
            "Epoch 4/15\n",
            "2137/2137 [==============================] - 0s 192us/step - loss: 3.8716 - accuracy: 0.0346 - val_loss: 3.8878 - val_accuracy: 0.0354\n",
            "Epoch 5/15\n",
            "2137/2137 [==============================] - 0s 181us/step - loss: 3.8592 - accuracy: 0.0360 - val_loss: 3.8832 - val_accuracy: 0.0354\n",
            "Epoch 6/15\n",
            "2137/2137 [==============================] - 0s 193us/step - loss: 3.8372 - accuracy: 0.0440 - val_loss: 3.8852 - val_accuracy: 0.0354\n",
            "Epoch 7/15\n",
            "2137/2137 [==============================] - 0s 186us/step - loss: 3.8127 - accuracy: 0.0496 - val_loss: 3.8871 - val_accuracy: 0.0354\n",
            "Epoch 8/15\n",
            "2137/2137 [==============================] - 0s 189us/step - loss: 3.8045 - accuracy: 0.0496 - val_loss: 3.8792 - val_accuracy: 0.0442\n",
            "Epoch 9/15\n",
            "2137/2137 [==============================] - 0s 181us/step - loss: 3.7705 - accuracy: 0.0632 - val_loss: 3.9027 - val_accuracy: 0.0531\n",
            "Epoch 10/15\n",
            "2137/2137 [==============================] - 0s 183us/step - loss: 3.7246 - accuracy: 0.0618 - val_loss: 3.8422 - val_accuracy: 0.0442\n",
            "Epoch 11/15\n",
            "2137/2137 [==============================] - 0s 186us/step - loss: 3.6631 - accuracy: 0.0781 - val_loss: 3.8374 - val_accuracy: 0.0708\n",
            "Epoch 12/15\n",
            "2137/2137 [==============================] - 0s 179us/step - loss: 3.6013 - accuracy: 0.0889 - val_loss: 3.8593 - val_accuracy: 0.0619\n",
            "Epoch 13/15\n",
            "2137/2137 [==============================] - 0s 182us/step - loss: 3.4890 - accuracy: 0.1104 - val_loss: 3.9058 - val_accuracy: 0.0708\n",
            "Epoch 14/15\n",
            "2137/2137 [==============================] - 0s 188us/step - loss: 3.3258 - accuracy: 0.1502 - val_loss: 3.8455 - val_accuracy: 0.0885\n",
            "Epoch 15/15\n",
            "2137/2137 [==============================] - 0s 180us/step - loss: 3.1216 - accuracy: 0.1867 - val_loss: 3.9333 - val_accuracy: 0.1150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fd06201d940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt-3_ZNGb9O6"
      },
      "source": [
        "y_pred = model.predict(np.array(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "hR43zse5cfxH",
        "outputId": "6b7288cb-532f-4e39-de28-2bd32494df15"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00123343, 0.02901449, 0.01839048, ..., 0.00506606, 0.01445343,\n",
              "        0.02150319],\n",
              "       [0.00190308, 0.02762362, 0.00829851, ..., 0.00856693, 0.05309406,\n",
              "        0.01701066],\n",
              "       [0.01080716, 0.03386877, 0.00304045, ..., 0.02344253, 0.01555482,\n",
              "        0.01889009],\n",
              "       ...,\n",
              "       [0.00484491, 0.00998049, 0.00386896, ..., 0.007606  , 0.02594477,\n",
              "        0.03630941],\n",
              "       [0.01016528, 0.01006909, 0.00534534, ..., 0.00889059, 0.02079046,\n",
              "        0.05381718],\n",
              "       [0.00033147, 0.03398509, 0.01233465, ..., 0.00364451, 0.00721719,\n",
              "        0.01219828]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtz8cPGHcLRD"
      },
      "source": [
        "y_pred=pd.DataFrame(y_pred)\n",
        "y_pred=y_pred.eq(y_pred.where(y_pred != 0).max(1), axis=0).astype(int)\n",
        "y_pred=y_pred.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "ma0Q7o31ckg5",
        "outputId": "a2e4aef5-7310-4957-bdac-7372c5115a5a"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBJkkz7IcL-p"
      },
      "source": [
        "y_test=pd.DataFrame(y_test)\n",
        "y_test=y_test.eq(y_test.where(y_test != 0).max(1), axis=0).astype(int)\n",
        "y_test=y_test.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INSdMmE7cCek"
      },
      "source": [
        "result=[]\n",
        "for i in range(0,len(y_test)):\n",
        "  for j in range(0,len(y_test[0])):\n",
        "    if(y_test[i][j]==1):\n",
        "      result.append(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAR7wc6TcSFk"
      },
      "source": [
        "predicted=[]\n",
        "for i in range(0,len(y_pred)):\n",
        "  for j in range(0,len(y_pred[0])):\n",
        "    if(y_pred[i][j]==1):\n",
        "      predicted.append(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "SSZYamwRcXsb",
        "outputId": "05bf4375-d7d8-4b23-8bce-0478b24c0686"
      },
      "source": [
        "print(result)\n",
        "print(predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 31, 24, 35, 37, 12, 45, 19, 0, 32, 23, 5, 16, 27, 45, 11, 13, 30, 47, 30, 27, 30, 23, 15, 7, 35, 17, 37, 29, 17, 31, 48, 15, 26, 36, 17, 27, 22, 32, 25, 11, 7, 38, 23, 16, 33, 23, 4, 36, 2, 48, 1, 40, 39, 34, 21, 45, 34, 18, 32, 32, 18, 41, 6, 48, 19, 11, 41, 43, 38, 15, 29, 30, 35, 42, 46, 8, 21, 40, 3, 15, 1, 12, 24, 27, 39, 23, 39, 20, 2, 47, 9, 9, 12, 29, 46, 44, 27, 44, 25, 28, 20, 6, 7, 31, 43, 20, 16, 5, 6, 8, 17, 42, 10, 33, 14, 13, 49, 1, 46, 22, 2, 13, 42, 8, 44, 25, 34, 41, 47, 0, 0, 11, 3, 28, 36, 45, 38, 42, 12, 13, 43, 6, 26, 24, 35, 29, 18, 24, 43, 10, 43, 16, 38, 44, 49, 13, 8, 39, 40, 31, 29, 14, 16, 49, 41, 0, 12, 5, 37, 7, 47, 4, 49, 14, 30, 46, 41, 35, 46, 20, 14, 9, 38, 10, 25, 10, 26, 22, 44, 3, 33, 28, 21, 11, 34, 9, 4, 48, 21, 19, 6, 3, 25, 37, 42, 1, 21, 22, 40, 1, 8, 10, 19, 4, 15, 17, 47, 39, 7, 37, 48, 24, 5, 20, 5, 36, 31, 36, 9, 2, 4, 26, 19, 28, 18, 26, 0, 33, 28, 3, 18, 14, 32, 45, 34, 33, 22, 40, 49]\n",
            "[24, 18, 18, 48, 2, 3, 26, 28, 21, 28, 47, 13, 44, 0, 45, 47, 8, 5, 40, 21, 20, 37, 49, 46, 31, 0, 39, 22, 30, 0, 21, 0, 35, 48, 2, 12, 0, 38, 49, 25, 7, 28, 22, 13, 9, 47, 2, 19, 9, 13, 34, 21, 40, 32, 28, 21, 28, 49, 30, 22, 32, 48, 41, 49, 21, 31, 31, 30, 18, 48, 1, 42, 3, 5, 42, 34, 0, 49, 40, 48, 49, 21, 24, 12, 16, 34, 36, 2, 18, 21, 22, 0, 21, 45, 24, 0, 24, 13, 33, 25, 30, 26, 10, 18, 26, 42, 15, 18, 29, 32, 26, 10, 28, 28, 21, 5, 14, 28, 2, 3, 45, 27, 11, 40, 2, 41, 25, 24, 33, 8, 19, 22, 21, 30, 8, 18, 17, 46, 48, 8, 43, 28, 16, 30, 36, 10, 0, 17, 33, 30, 12, 34, 46, 42, 24, 22, 32, 3, 28, 16, 45, 28, 24, 47, 49, 48, 27, 12, 22, 43, 49, 47, 12, 12, 30, 30, 16, 3, 0, 49, 28, 2, 3, 21, 28, 25, 9, 40, 49, 30, 21, 41, 48, 9, 10, 36, 9, 24, 35, 19, 20, 32, 3, 25, 32, 28, 3, 0, 28, 40, 21, 2, 28, 28, 0, 9, 9, 24, 0, 13, 40, 48, 32, 18, 28, 48, 42, 21, 42, 48, 21, 5, 32, 47, 19, 30, 3, 46, 35, 48, 27, 41, 21, 10, 45, 0, 21, 41, 42, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "n8eJn2DkcZR7",
        "outputId": "68d87f06-6565-4c1e-fb2e-303cb3f25e41"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(result,predicted)\n",
        "\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 1, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 1, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eAG9TSwPcdja",
        "outputId": "a0b8587f-f061-4eed-ab40-33ee80a5ab70"
      },
      "source": [
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "print('Confusion Matrix :')\n",
        "print(cm) \n",
        "print('Accuracy Score :',accuracy_score(result, predicted)) \n",
        "print('Report : ')\n",
        "print(classification_report(result, predicted)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 1 0 0]\n",
            " [1 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 1]]\n",
            "Accuracy Score : 0.084\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         5\n",
            "           1       0.00      0.00      0.00         5\n",
            "           2       0.00      0.00      0.00         5\n",
            "           3       0.11      0.20      0.14         5\n",
            "           4       0.00      0.00      0.00         5\n",
            "           5       0.00      0.00      0.00         5\n",
            "           6       0.00      0.00      0.00         5\n",
            "           7       0.00      0.00      0.00         5\n",
            "           8       0.00      0.00      0.00         5\n",
            "           9       0.14      0.20      0.17         5\n",
            "          10       0.00      0.00      0.00         5\n",
            "          11       0.00      0.00      0.00         5\n",
            "          12       0.17      0.20      0.18         5\n",
            "          13       0.00      0.00      0.00         5\n",
            "          14       0.00      0.00      0.00         5\n",
            "          15       0.00      0.00      0.00         5\n",
            "          16       0.00      0.00      0.00         5\n",
            "          17       0.00      0.00      0.00         5\n",
            "          18       0.00      0.00      0.00         5\n",
            "          19       0.00      0.00      0.00         5\n",
            "          20       0.00      0.00      0.00         5\n",
            "          21       0.06      0.20      0.09         5\n",
            "          22       0.00      0.00      0.00         5\n",
            "          23       0.00      0.00      0.00         5\n",
            "          24       0.00      0.00      0.00         5\n",
            "          25       1.00      1.00      1.00         5\n",
            "          26       0.00      0.00      0.00         5\n",
            "          27       0.00      0.00      0.00         5\n",
            "          28       0.00      0.00      0.00         5\n",
            "          29       0.00      0.00      0.00         5\n",
            "          30       0.09      0.20      0.13         5\n",
            "          31       0.00      0.00      0.00         5\n",
            "          32       0.12      0.20      0.15         5\n",
            "          33       0.00      0.00      0.00         5\n",
            "          34       0.00      0.00      0.00         5\n",
            "          35       0.00      0.00      0.00         5\n",
            "          36       0.00      0.00      0.00         5\n",
            "          37       0.00      0.00      0.00         5\n",
            "          38       0.00      0.00      0.00         5\n",
            "          39       0.00      0.00      0.00         5\n",
            "          40       0.43      0.60      0.50         5\n",
            "          41       0.20      0.20      0.20         5\n",
            "          42       0.14      0.20      0.17         5\n",
            "          43       0.00      0.00      0.00         5\n",
            "          44       0.00      0.00      0.00         5\n",
            "          45       0.40      0.40      0.40         5\n",
            "          46       0.00      0.00      0.00         5\n",
            "          47       0.17      0.20      0.18         5\n",
            "          48       0.08      0.20      0.12         5\n",
            "          49       0.10      0.20      0.13         5\n",
            "\n",
            "    accuracy                           0.08       250\n",
            "   macro avg       0.06      0.08      0.07       250\n",
            "weighted avg       0.06      0.08      0.07       250\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}