{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glove_Capsules.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_QcuetwYo9K"
      },
      "source": [
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "from keras.engine import Layer\n",
        "from keras.layers import Activation, Add, Bidirectional, Conv1D, Dense, Dropout, Embedding, Flatten\n",
        "from keras.layers import concatenate, GRU, Input, LSTM, MaxPooling1D\n",
        "from keras.layers import GlobalAveragePooling1D,  GlobalMaxPooling1D, SpatialDropout1D\n",
        "from keras.models import Model\n",
        "import keras.backend as k\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import text, sequence\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo2iwCxZbQFw"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.test.utils import common_texts, get_tmpfile\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn import metrics\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.initializers import *\n",
        "from keras.optimizers import *\n",
        "import keras.backend as K\n",
        "from keras.callbacks import *\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from smart_open import smart_open\n",
        "import datetime \n",
        "\n",
        "\n",
        "import os\n",
        "import time\n",
        "import gc\n",
        "import re\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkdyYATxbV39"
      },
      "source": [
        "gru_len = 128\n",
        "Routings = 5\n",
        "Num_capsule = 10\n",
        "Dim_capsule = 16\n",
        "dropout_p = 0.3\n",
        "rate_drop_dense = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wruuejzbaBV"
      },
      "source": [
        "def squash(x, axis=-1):\n",
        "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
        "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
        "    return scale * x\n",
        "\n",
        "\n",
        "# define our own softmax function instead of K.softmax\n",
        "# because K.softmax can not specify axis.\n",
        "def softmax(x, axis=-1):\n",
        "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
        "    return ex / K.sum(ex, axis=axis, keepdims=True)\n",
        "\n",
        "\n",
        "# define the margin loss like hinge loss\n",
        "def margin_loss(y_true, y_pred):\n",
        "    lamb, margin = 0.5, 0.1\n",
        "    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
        "        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)\n",
        "\n",
        "\n",
        "class Capsule(Layer):\n",
        "    \"\"\"A Capsule Implement with Pure Keras\n",
        "    There are two vesions of Capsule.\n",
        "    One is like dense layer (for the fixed-shape input),\n",
        "    and the other is like timedistributed dense (for various length input).\n",
        "\n",
        "    The input shape of Capsule must be (batch_size,\n",
        "                                        input_num_capsule,\n",
        "                                        input_dim_capsule\n",
        "                                       )\n",
        "    and the output shape is (batch_size,\n",
        "                             num_capsule,\n",
        "                             dim_capsule\n",
        "                            )\n",
        "\n",
        "    Capsule Implement is from https://github.com/bojone/Capsule/\n",
        "    Capsule Paper: https://arxiv.org/abs/1710.09829\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_capsule,\n",
        "                 dim_capsule,\n",
        "                 routings=3,\n",
        "                 share_weights=True,\n",
        "                 activation='squash',\n",
        "                 **kwargs):\n",
        "        super(Capsule, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.share_weights = share_weights\n",
        "        if activation == 'squash':\n",
        "            self.activation = squash\n",
        "        else:\n",
        "            self.activation = activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim_capsule = input_shape[-1]\n",
        "        if self.share_weights:\n",
        "            self.kernel = self.add_weight(\n",
        "                name='capsule_kernel',\n",
        "                shape=(1, input_dim_capsule,\n",
        "                       self.num_capsule * self.dim_capsule),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "        else:\n",
        "            input_num_capsule = input_shape[-2]\n",
        "            self.kernel = self.add_weight(\n",
        "                name='capsule_kernel',\n",
        "                shape=(input_num_capsule, input_dim_capsule,\n",
        "                       self.num_capsule * self.dim_capsule),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Following the routing algorithm from Hinton's paper,\n",
        "        but replace b = b + <u,v> with b = <u,v>.\n",
        "\n",
        "        This change can improve the feature representation of Capsule.\n",
        "\n",
        "        However, you can replace\n",
        "            b = K.batch_dot(outputs, hat_inputs, [2, 3])\n",
        "        with\n",
        "            b += K.batch_dot(outputs, hat_inputs, [2, 3])\n",
        "        to realize a standard routing.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.share_weights:\n",
        "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
        "        else:\n",
        "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
        "\n",
        "        batch_size = K.shape(inputs)[0]\n",
        "        input_num_capsule = K.shape(inputs)[1]\n",
        "        hat_inputs = K.reshape(hat_inputs,\n",
        "                               (batch_size, input_num_capsule,\n",
        "                                self.num_capsule, self.dim_capsule))\n",
        "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
        "\n",
        "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
        "        for i in range(self.routings):\n",
        "            c = softmax(b, 1)\n",
        "            o = self.activation(K.batch_dot(c, hat_inputs, [2, 2]))\n",
        "            if i < self.routings - 1:\n",
        "                b = K.batch_dot(o, hat_inputs, [2, 3])\n",
        "                if K.backend() == 'theano':\n",
        "                    o = K.sum(o, axis=1)\n",
        "\n",
        "        return o\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (None, self.num_capsule, self.dim_capsule)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j8yI7LqbiTM"
      },
      "source": [
        "#Importing the dataset\n",
        "import pandas as pd\n",
        " \n",
        "dataset =pd.read_csv('Abstract_Author.csv')\n",
        "\n",
        "#dataset.iloc[:,0:1].fillna('other', inplace=True)\n",
        "#y=dataset.iloc[:,1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbz8-Xz-bsia"
      },
      "source": [
        "k=0\n",
        "X_train=[]\n",
        "y_train=[]\n",
        "for i in range(0,155):\n",
        "  for j in range(k,k+40):\n",
        "    X_train.append(dataset.iloc[j,0])\n",
        "    y_train.append(dataset.iloc[j,1])\n",
        "  k+=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD-J4aDRb4OM"
      },
      "source": [
        "k=40\n",
        "X_test=[]\n",
        "y_test=[]\n",
        "for i in range(0,155):\n",
        "  for j in range(k,k+10):\n",
        "    X_test.append(dataset.iloc[j,0])\n",
        "    y_test.append(dataset.iloc[j,1])\n",
        "  k+=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWYi0rxwcGMj"
      },
      "source": [
        "X_train=pd.DataFrame(X_train)\n",
        "X_test=pd.DataFrame(X_test)\n",
        "y_train=pd.DataFrame(y_train)\n",
        "y_test=pd.DataFrame(y_test)\n",
        "X_train=X_train.iloc[:,:].values\n",
        "X_test=X_test.iloc[:,:].values\n",
        "y_train=y_train.iloc[:,:].values\n",
        "y_test=y_test.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpfWGsOYcbRX"
      },
      "source": [
        "train=np.concatenate((X_train,y_train),axis=1)\n",
        "test=np.concatenate((X_test,y_test),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgDQWT_BcdbJ"
      },
      "source": [
        "np.random.shuffle(train)\n",
        "np.random.shuffle(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvWFtL_hcfh4"
      },
      "source": [
        "train=pd.DataFrame(train)\n",
        "test=pd.DataFrame(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8qQQY3_cm5n"
      },
      "source": [
        "X_train=train.iloc[:,0]\n",
        "X_test=test.iloc[:,0]\n",
        "y_train=train.iloc[:,1]\n",
        "y_test=test.iloc[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTeTIURQcs3_"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_train)\n",
        "encoded_Y = encoder.transform(y_train)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "y_train = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP0JyA67cvR4"
      },
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_test)\n",
        "encoded_Y = encoder.transform(y_test)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "y_test = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmTa9QDec1E7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bd244119-7fe6-4756-9ccf-43a33dbfc476"
      },
      "source": [
        "#!unzip \"/content/drive/My Drive/1835_3176_compressed_glove.6B.100d.txt.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/1835_3176_compressed_glove.6B.100d.txt.zip\n",
            "  inflating: glove.6B.100d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuPPLL8XdRKc"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#Tokenize the sentences\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(list((X_train)))\n",
        "\n",
        "#converting text into integer sequences\n",
        "X_train  = tokenizer.texts_to_sequences(X_train) \n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "#padding to prepare sequences of same length\n",
        "X_train  = pad_sequences(X_train, maxlen=1200)\n",
        "X_test = pad_sequences(X_test, maxlen=1200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOzBG6SJdziq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "684ebc2f-d8a0-40c4-e216-62b7630a64dc"
      },
      "source": [
        "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
        "print(size_of_vocabulary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7b07O6Oc5xN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c852a17-9d92-4617-ef0b-abc596c215c3"
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open('/content/glove.6B.100d.txt')\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evTBcEvFeKjZ"
      },
      "source": [
        "embedding_matrix = np.zeros((size_of_vocabulary, 100))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8TMzqCjePcO"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(X_train,y_train, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0t-0cqGedY3"
      },
      "source": [
        " \n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw41FdjaehC5"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import AveragePooling1D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuKYTGFDejGv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "da5c58d2-2a99-46be-e4ad-2a5b39d157db"
      },
      "source": [
        "classifier = Sequential()\n",
        "classifier.add(Embedding(size_of_vocabulary,100,weights=[embedding_matrix],input_length=500,trainable=False)) \n",
        "classifier.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "classifier.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "classifier.add(AveragePooling1D(3))\n",
        "classifier.add(Flatten())\n",
        "#classifier.add(Dense(100, activation='relu'))\n",
        "classifier.add(Dense(155, activation='softmax'))\n",
        "classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 100)          2055500   \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 498, 128)          38528     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 496, 64)           24640     \n",
            "_________________________________________________________________\n",
            "capsule_1 (Capsule)          (None, 1, 1, 72)          4608      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 72)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 155)               11315     \n",
            "=================================================================\n",
            "Total params: 2,134,591\n",
            "Trainable params: 79,091\n",
            "Non-trainable params: 2,055,500\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfLxzBqIemw_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "6ba6b2b1-3dbf-4187-d853-3012b7fcb3aa"
      },
      "source": [
        "classifier.fit((X_train),(y_train),batch_size=128,epochs=15,validation_data=(np.array(X_eval),np.array(y_eval)),verbose=1,callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "37/37 [==============================] - 20s 532ms/step - loss: 2.0823 - accuracy: 0.9273 - val_loss: 2.8422 - val_accuracy: 0.5684\n",
            "Epoch 2/15\n",
            "37/37 [==============================] - 20s 533ms/step - loss: 2.0046 - accuracy: 0.9357 - val_loss: 2.8241 - val_accuracy: 0.5710\n",
            "Epoch 3/15\n",
            "37/37 [==============================] - 20s 540ms/step - loss: 1.9345 - accuracy: 0.9381 - val_loss: 2.7624 - val_accuracy: 0.5684\n",
            "Epoch 4/15\n",
            "37/37 [==============================] - 20s 534ms/step - loss: 1.8646 - accuracy: 0.9469 - val_loss: 2.7223 - val_accuracy: 0.5723\n",
            "Epoch 5/15\n",
            "37/37 [==============================] - 20s 532ms/step - loss: 1.7815 - accuracy: 0.9544 - val_loss: 2.6781 - val_accuracy: 0.5897\n",
            "Epoch 6/15\n",
            "37/37 [==============================] - 20s 534ms/step - loss: 1.7097 - accuracy: 0.9572 - val_loss: 2.6413 - val_accuracy: 0.5923\n",
            "Epoch 7/15\n",
            "37/37 [==============================] - 20s 530ms/step - loss: 1.6434 - accuracy: 0.9606 - val_loss: 2.6041 - val_accuracy: 0.5852\n",
            "Epoch 8/15\n",
            "37/37 [==============================] - 20s 530ms/step - loss: 1.5765 - accuracy: 0.9647 - val_loss: 2.5771 - val_accuracy: 0.5942\n",
            "Epoch 9/15\n",
            "37/37 [==============================] - 20s 542ms/step - loss: 1.5106 - accuracy: 0.9684 - val_loss: 2.5391 - val_accuracy: 0.5916\n",
            "Epoch 10/15\n",
            "37/37 [==============================] - 20s 541ms/step - loss: 1.4620 - accuracy: 0.9692 - val_loss: 2.5182 - val_accuracy: 0.6032\n",
            "Epoch 11/15\n",
            "37/37 [==============================] - 20s 537ms/step - loss: 1.3980 - accuracy: 0.9731 - val_loss: 2.4538 - val_accuracy: 0.6039\n",
            "Epoch 12/15\n",
            "37/37 [==============================] - 20s 536ms/step - loss: 1.3261 - accuracy: 0.9746 - val_loss: 2.4586 - val_accuracy: 0.5884\n",
            "Epoch 13/15\n",
            "37/37 [==============================] - 20s 533ms/step - loss: 1.2731 - accuracy: 0.9791 - val_loss: 2.4215 - val_accuracy: 0.5955\n",
            "Epoch 14/15\n",
            "37/37 [==============================] - 20s 530ms/step - loss: 1.2252 - accuracy: 0.9794 - val_loss: 2.3776 - val_accuracy: 0.6071\n",
            "Epoch 15/15\n",
            "31/37 [========================>.....] - ETA: 2s - loss: 1.1668 - accuracy: 0.9826"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r_tejsFfEvX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bdea46f7-6288-4be1-98da-b1f1f234f5e0"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4773, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3veNhJEgfJq_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "588e9ade-d012-4037-be3a-3a124b612999"
      },
      "source": [
        "  y_pred = classifier.predict(np.array(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 300) for input Tensor(\"embedding_6_input:0\", shape=(None, 300), dtype=float32), but it was called on an input with incompatible shape (None, 310).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QRRYu6LKE7G"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9YI1OsuFjbU"
      },
      "source": [
        "y_pred=pd.DataFrame(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEIuK9rzFr1C"
      },
      "source": [
        "y_pred.to_csv('/content/submission_sentiment_8.csv', header=True, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klxz9c9dhdTt"
      },
      "source": [
        "y_pred=pd.DataFrame(y_pred)\n",
        "y_pred=y_pred.eq(y_pred.where(y_pred != 0).max(1), axis=0).astype(int)\n",
        "y_pred=y_pred.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3phMAcUhjAk"
      },
      "source": [
        "y_test=pd.DataFrame(y_test)\n",
        "y_test=y_test.eq(y_test.where(y_test != 0).max(1), axis=0).astype(int)\n",
        "y_test=y_test.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJO4xheDhk0E"
      },
      "source": [
        "result=[]\n",
        "for i in range(0,len(y_test)):\n",
        "  for j in range(0,len(y_test[0])):\n",
        "    if(y_test[i][j]==1):\n",
        "      result.append(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CC23dPphmc4"
      },
      "source": [
        "predicted=[]\n",
        "for i in range(0,len(y_pred)):\n",
        "  for j in range(0,len(y_pred[0])):\n",
        "    if(y_pred[i][j]==1):\n",
        "      predicted.append(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwEd0Q2vhoJm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "20c09f0d-b87b-436c-8db1-f376d874ba4f"
      },
      "source": [
        "print(result)\n",
        "print(predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 14, 6, 28, 16, 19, 28, 16, 29, 27, 34, 41, 10, 7, 18, 27, 34, 49, 5, 29, 2, 34, 0, 6, 45, 26, 34, 48, 10, 26, 15, 11, 15, 43, 0, 31, 38, 47, 30, 12, 42, 21, 16, 17, 1, 42, 4, 19, 42, 48, 48, 39, 24, 11, 9, 24, 38, 15, 13, 16, 29, 22, 6, 36, 39, 26, 11, 37, 23, 18, 3, 13, 27, 21, 21, 40, 17, 16, 20, 35, 28, 41, 38, 13, 3, 48, 35, 32, 11, 27, 5, 28, 2, 29, 19, 8, 35, 16, 23, 42, 40, 44, 31, 30, 23, 30, 41, 37, 7, 10, 37, 29, 9, 26, 39, 16, 40, 33, 26, 45, 22, 29, 21, 30, 9, 21, 44, 14, 2, 47, 22, 22, 32, 48, 16, 38, 1, 0, 39, 49, 33, 7, 45, 10, 42, 44, 44, 20, 17, 35, 26, 47, 19, 43, 36, 38, 47, 25, 22, 26, 11, 39, 22, 46, 33, 16, 10, 8, 3, 1, 31, 13, 3, 39, 7, 1, 15, 40, 10, 13, 13, 27, 5, 14, 25, 35, 36, 32, 10, 6, 46, 1, 49, 40, 1, 43, 48, 32, 0, 29, 38, 2, 9, 5, 29, 34, 39, 7, 20, 17, 20, 45, 42, 1, 9, 43, 36, 40, 41, 7, 14, 13, 12, 24, 48, 18, 41, 37, 31, 4, 17, 35, 28, 3, 17, 22, 23, 7, 23, 30, 2, 3, 20, 4, 21, 14, 26, 10, 19, 41, 4, 7, 0, 6, 36, 18, 37, 9, 0, 45, 17, 17, 3, 45, 9, 34, 19, 44, 38, 3, 24, 21, 14, 32, 27, 13, 43, 23, 21, 43, 40, 0, 39, 31, 24, 41, 15, 27, 19, 37, 29, 46, 36, 44, 6, 43, 46, 38, 4, 48, 4, 20, 33, 24, 30, 40, 26, 13, 31, 45, 27, 28, 6, 31, 4, 49, 36, 22, 47, 28, 45, 5, 42, 37, 34, 1, 46, 6, 46, 32, 20, 23, 8, 17, 25, 35, 41, 27, 2, 47, 4, 46, 31, 46, 32, 24, 14, 43, 49, 19, 36, 15, 46, 2, 38, 49, 32, 28, 30, 26, 33, 9, 3, 15, 15, 8, 4, 23, 1, 49, 28, 25, 33, 15, 40, 6, 30, 12, 23, 18, 32, 21, 33, 22, 11, 7, 39, 38, 36, 46, 24, 34, 25, 25, 22, 49, 32, 21, 8, 9, 5, 34, 37, 33, 16, 20, 18, 4, 8, 40, 5, 8, 18, 27, 31, 14, 23, 12, 47, 7, 25, 25, 37, 14, 36, 17, 25, 1, 5, 18, 28, 33, 35, 11, 20, 35, 30, 42, 42, 12, 48, 2, 15, 10, 45, 12, 14, 39, 24, 19, 44, 3, 31, 2, 5, 37, 10, 19, 11, 41, 47, 0, 6, 8, 49, 2, 8, 5, 12, 45, 12, 35, 47, 0, 25, 44, 42, 11, 20, 12, 11, 34, 13, 9, 18, 12, 8, 49, 48, 29, 47, 30, 44, 33, 43, 44, 41, 24, 18, 43]\n",
            "[12, 44, 6, 28, 24, 32, 28, 9, 29, 5, 34, 41, 24, 43, 32, 11, 14, 49, 25, 29, 18, 40, 8, 6, 45, 26, 34, 48, 10, 43, 3, 16, 27, 11, 5, 31, 38, 47, 30, 11, 5, 20, 16, 17, 1, 16, 4, 2, 11, 48, 48, 39, 11, 26, 21, 35, 5, 21, 13, 16, 29, 20, 6, 11, 39, 25, 11, 34, 23, 11, 16, 13, 27, 16, 38, 40, 17, 7, 2, 35, 28, 41, 38, 13, 29, 48, 30, 2, 26, 27, 2, 28, 18, 16, 10, 2, 35, 25, 6, 16, 40, 44, 31, 30, 23, 30, 41, 28, 12, 11, 37, 15, 11, 26, 39, 16, 40, 33, 29, 45, 29, 29, 10, 30, 9, 10, 44, 34, 11, 47, 11, 25, 32, 48, 29, 25, 1, 24, 39, 49, 33, 42, 45, 10, 42, 44, 44, 36, 17, 35, 9, 47, 28, 43, 5, 38, 44, 10, 11, 43, 43, 39, 2, 28, 33, 3, 29, 36, 15, 1, 31, 33, 21, 39, 7, 1, 16, 40, 19, 13, 13, 27, 10, 44, 11, 35, 36, 10, 43, 6, 46, 1, 49, 40, 1, 43, 48, 40, 11, 7, 38, 10, 24, 43, 26, 34, 39, 7, 2, 17, 8, 45, 25, 1, 15, 43, 36, 34, 41, 7, 47, 24, 12, 11, 48, 26, 37, 37, 31, 4, 17, 35, 28, 3, 17, 2, 23, 9, 23, 30, 2, 10, 36, 4, 29, 14, 26, 25, 37, 41, 4, 16, 20, 6, 26, 5, 37, 18, 5, 45, 17, 17, 16, 45, 10, 37, 19, 44, 29, 3, 8, 15, 44, 32, 36, 13, 7, 23, 45, 38, 40, 5, 39, 31, 0, 41, 43, 37, 40, 37, 29, 46, 20, 44, 6, 43, 46, 0, 4, 48, 4, 0, 33, 9, 30, 40, 13, 13, 31, 45, 27, 28, 6, 31, 4, 49, 36, 3, 47, 28, 45, 2, 42, 37, 46, 1, 46, 34, 46, 32, 10, 23, 22, 17, 0, 35, 41, 0, 25, 47, 4, 46, 31, 46, 32, 38, 37, 36, 49, 19, 5, 38, 46, 38, 5, 49, 10, 28, 30, 26, 33, 0, 11, 16, 3, 2, 4, 23, 1, 49, 37, 24, 33, 21, 40, 6, 30, 35, 23, 20, 24, 9, 33, 26, 38, 43, 46, 10, 36, 40, 24, 34, 5, 12, 5, 49, 32, 36, 40, 5, 40, 34, 28, 33, 38, 22, 2, 4, 37, 34, 2, 0, 38, 0, 31, 44, 34, 36, 47, 35, 20, 2, 37, 41, 36, 17, 10, 1, 11, 11, 28, 33, 35, 26, 10, 35, 30, 9, 42, 12, 48, 24, 3, 5, 45, 21, 14, 39, 2, 10, 37, 29, 31, 2, 5, 37, 10, 34, 11, 41, 47, 5, 6, 8, 49, 2, 5, 44, 5, 45, 0, 35, 44, 8, 21, 40, 21, 8, 20, 11, 9, 46, 5, 9, 36, 1, 10, 49, 48, 9, 47, 30, 44, 33, 26, 44, 41, 5, 11, 26]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDBLiu4ZhrEo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "df8aa6a7-c875-43bb-df02-2231c2fec9c1"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(result,predicted)\n",
        "\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0, 10,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0,  3, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  8,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0, 10,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0, 10]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYjQr5KFhtTe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2330efac-8b26-4694-c04b-3ed2a9f0ec0b"
      },
      "source": [
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "print('Confusion Matrix :')\n",
        "print(cm) \n",
        "print('Accuracy Score :',accuracy_score(result, predicted)) \n",
        "print('Report : ')\n",
        "print(classification_report(result, predicted)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[ 0  0  0 ...  0  0  0]\n",
            " [ 0 10  0 ...  0  0  0]\n",
            " [ 0  0  3 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  8  0  0]\n",
            " [ 0  0  0 ...  0 10  0]\n",
            " [ 0  0  0 ...  0  0 10]]\n",
            "Accuracy Score : 0.512\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        10\n",
            "           1       0.91      1.00      0.95        10\n",
            "           2       0.18      0.30      0.22        10\n",
            "           3       0.29      0.20      0.24        10\n",
            "           4       1.00      1.00      1.00        10\n",
            "           5       0.05      0.10      0.07        10\n",
            "           6       0.90      0.90      0.90        10\n",
            "           7       0.50      0.30      0.37        10\n",
            "           8       0.17      0.10      0.12        10\n",
            "           9       0.20      0.20      0.20        10\n",
            "          10       0.16      0.30      0.21        10\n",
            "          11       0.09      0.20      0.13        10\n",
            "          12       0.40      0.20      0.27        10\n",
            "          13       0.88      0.70      0.78        10\n",
            "          14       0.67      0.20      0.31        10\n",
            "          15       0.00      0.00      0.00        10\n",
            "          16       0.23      0.30      0.26        10\n",
            "          17       1.00      1.00      1.00        10\n",
            "          18       0.00      0.00      0.00        10\n",
            "          19       0.67      0.20      0.31        10\n",
            "          20       0.14      0.10      0.12        10\n",
            "          21       0.00      0.00      0.00        10\n",
            "          22       0.00      0.00      0.00        10\n",
            "          23       1.00      0.80      0.89        10\n",
            "          24       0.11      0.10      0.11        10\n",
            "          25       0.00      0.00      0.00        10\n",
            "          26       0.31      0.40      0.35        10\n",
            "          27       0.80      0.40      0.53        10\n",
            "          28       0.69      0.90      0.78        10\n",
            "          29       0.38      0.50      0.43        10\n",
            "          30       0.91      1.00      0.95        10\n",
            "          31       1.00      1.00      1.00        10\n",
            "          32       0.71      0.50      0.59        10\n",
            "          33       0.91      1.00      0.95        10\n",
            "          34       0.42      0.50      0.45        10\n",
            "          35       0.75      0.90      0.82        10\n",
            "          36       0.38      0.50      0.43        10\n",
            "          37       0.47      0.70      0.56        10\n",
            "          38       0.33      0.40      0.36        10\n",
            "          39       1.00      0.90      0.95        10\n",
            "          40       0.53      0.80      0.64        10\n",
            "          41       0.90      0.90      0.90        10\n",
            "          42       0.75      0.30      0.43        10\n",
            "          43       0.33      0.40      0.36        10\n",
            "          44       0.53      0.80      0.64        10\n",
            "          45       0.91      1.00      0.95        10\n",
            "          46       0.73      0.80      0.76        10\n",
            "          47       0.89      0.80      0.84        10\n",
            "          48       1.00      1.00      1.00        10\n",
            "          49       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           0.51       500\n",
            "   macro avg       0.52      0.51      0.50       500\n",
            "weighted avg       0.52      0.51      0.50       500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EvRwa6whwEW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}