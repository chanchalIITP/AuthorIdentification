{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tfidf_kervolution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPNpIEKeCqlv"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets,transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEHi9P_2Ct2V"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.ops import nn\n",
        "from tensorflow.python.keras import activations, regularizers, initializers, constraints, engine\n",
        "from tensorflow.python.keras.utils import conv_utils\n",
        "from tensorflow.python.keras.layers import Layer, deserialize, Conv1D\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.ops import array_ops\n",
        "\n",
        "\n",
        "__all__ = ['KernelConv2D']\n",
        "\n",
        "\n",
        "class KernelConv2D(Layer):\n",
        "    \"\"\"2D convolution layer (e.g. spatial convolution over images).\n",
        "    This layer creates a convolution kernel that is convolved\n",
        "    with the layer input to produce a tensor of\n",
        "    outputs. If `use_bias` is True,\n",
        "    a bias vector is created and added to the outputs. Finally, if\n",
        "    `activation` is not `None`, it is applied to the outputs as well.\n",
        "    When using this layer as the first layer in a model,\n",
        "    provide the keyword argument `input_shape`\n",
        "    (tuple of integers, does not include the sample axis),\n",
        "    e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
        "    in `data_format=\"channels_last\"`.\n",
        "    # Arguments\n",
        "        filters: Integer, the dimensionality of the output space\n",
        "            (i.e. the number of output filters in the convolution).\n",
        "        kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
        "            height and width of the 2D convolution window.\n",
        "            Can be a single integer to specify the same value for\n",
        "            all spatial dimensions.\n",
        "        kernel_function: A layer takes the columnized feature and the kernel as its inputs.\n",
        "        strides: An integer or tuple/list of 2 integers,\n",
        "            specifying the strides of the convolution\n",
        "            along the height and width.\n",
        "            Can be a single integer to specify the same value for\n",
        "            all spatial dimensions.\n",
        "            Specifying any stride value != 1 is incompatible with specifying\n",
        "            any `dilation_rate` value != 1.\n",
        "        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
        "            Note that `\"same\"` is slightly inconsistent across backends with\n",
        "            `strides` != 1, as described\n",
        "            [here](https://github.com/keras-team/keras/pull/9473#issuecomment-372166860)\n",
        "        data_format: A string,\n",
        "            one of `\"channels_last\"` or `\"channels_first\"`.\n",
        "            The ordering of the dimensions in the inputs.\n",
        "            `\"channels_last\"` corresponds to inputs with shape\n",
        "            `(batch, height, width, channels)` while `\"channels_first\"`\n",
        "            corresponds to inputs with shape\n",
        "            `(batch, channels, height, width)`.\n",
        "            It defaults to the `image_data_format` value found in your\n",
        "            Keras config file at `~/.keras/keras.json`.\n",
        "            If you never set it, then it will be \"channels_last\".\n",
        "        dilation_rate: an integer or tuple/list of 2 integers, specifying\n",
        "            the dilation rate to use for dilated convolution.\n",
        "            Can be a single integer to specify the same value for\n",
        "            all spatial dimensions.\n",
        "            Currently, specifying any `dilation_rate` value != 1 is\n",
        "            incompatible with specifying any stride value != 1.\n",
        "        activation: Activation function to use\n",
        "            (see [activations](../activations.md)).\n",
        "            If you don't specify anything, no activation is applied\n",
        "            (ie. \"linear\" activation: `a(x) = x`).\n",
        "        use_bias: Boolean, whether the layer uses a bias vector.\n",
        "        kernel_initializer: Initializer for the `kernel` weights matrix.\n",
        "        bias_initializer: Initializer for the bias vector.\n",
        "        kernel_regularizer: Regularizer function applied to\n",
        "            the `kernel` weights matrix.\n",
        "        bias_regularizer: Regularizer function applied to the bias vector.\n",
        "        activity_regularizer: Regularizer function applied to\n",
        "            the output of the layer (its \"activation\").\n",
        "        kernel_constraint: Constraint function applied to the kernel matrix.\n",
        "        bias_constraint: Constraint function applied to the bias vector.\n",
        "    # Input shape\n",
        "        4D tensor with shape:\n",
        "        `(batch, channels, rows, cols)`\n",
        "        if `data_format` is `\"channels_first\"`\n",
        "        or 4D tensor with shape:\n",
        "        `(batch, rows, cols, channels)`\n",
        "        if `data_format` is `\"channels_last\"`.\n",
        "    # Output shape\n",
        "        4D tensor with shape:\n",
        "        `(batch, filters, new_rows, new_cols)`\n",
        "        if `data_format` is `\"channels_first\"`\n",
        "        or 4D tensor with shape:\n",
        "        `(batch, new_rows, new_cols, filters)`\n",
        "        if `data_format` is `\"channels_last\"`.\n",
        "        `rows` and `cols` values might have changed due to padding.\n",
        "    \"\"\"\n",
        "    def __init__(self, filters,\n",
        "                 kernel_size,\n",
        "                 kernel_function,\n",
        "                 strides=1,\n",
        "                 padding='valid',\n",
        "                 data_format=None,\n",
        "                 dilation_rate=1,\n",
        "                 activation=None,\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 **kwargs):\n",
        "        super(KernelConv2D, self).__init__(**kwargs)\n",
        "        self.rank = 1\n",
        "        self.filters = filters\n",
        "        self.kernel_function = kernel_function\n",
        "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, self.rank, 'kernel_size')\n",
        "        self.strides = conv_utils.normalize_tuple(strides, self.rank, 'strides')\n",
        "        self.padding = conv_utils.normalize_padding(padding)\n",
        "        self.data_format = conv_utils.normalize_data_format(data_format)\n",
        "        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, self.rank, 'dilation_rate')\n",
        "        self.activation = activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "        self.input_spec = engine.base_layer.InputSpec(ndim=self.rank + 2)\n",
        "\n",
        "        self.kernel = self.bias = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "        if input_shape.dims[channel_axis].value is None:\n",
        "            raise ValueError('The channel dimension of the inputs should be defined. Found `None`.')\n",
        "        input_dim = int(input_shape[channel_axis])\n",
        "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=kernel_shape,\n",
        "            initializer=self.kernel_initializer,\n",
        "            name='kernel',\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "        )\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "                shape=(self.filters,),\n",
        "                initializer=self.bias_initializer,\n",
        "                name='bias',\n",
        "                regularizer=self.bias_regularizer,\n",
        "                constraint=self.bias_constraint,\n",
        "            )\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "        self.input_spec = engine.base_layer.InputSpec(\n",
        "            ndim=self.rank + 2,\n",
        "            axes={channel_axis: input_dim},\n",
        "        )\n",
        "        self.kernel_function.build([input_shape, kernel_shape])\n",
        "        super(KernelConv2D, self).build(input_shape)\n",
        "\n",
        "    def _compute_causal_padding(self):\n",
        "      left_pad = self.dilation_rate[0] * (self.kernel_size[0] - 1)\n",
        "      if self.data_format == 'channels_last':\n",
        "        causal_padding = [[0, 0], [left_pad, 0], [0, 0]]\n",
        "      else:\n",
        "        causal_padding = [[0, 0], [0, 0], [left_pad, 0]]\n",
        "      return causal_padding\n",
        "\n",
        "    def call(self, inputs):\n",
        "        data_format = conv_utils.convert_data_format(self.data_format, self.rank + 2)\n",
        "        inputs, tf_data_format = K._preprocess_conv2d_input(inputs, self.data_format)\n",
        "\n",
        "        '''inputs = tf.compat.v1.extract_image_patches(\n",
        "            inputs,\n",
        "            ksizes=(1,) + K.int_shape(self.kernel)[:2] + (1,),\n",
        "            strides=(1,) + self.strides + (1,) + (1,) ,\n",
        "            rates=(1,) + self.dilation_rate + (1,) + (1,),\n",
        "            padding=self.padding.upper(),\n",
        "        )'''\n",
        "        inputs = array_ops.pad(inputs, self._compute_causal_padding())\n",
        "\n",
        "        kernel = K.reshape(self.kernel, (-1, self.filters))\n",
        "        outputs = self.kernel_function([inputs, kernel])\n",
        "\n",
        "        if self.data_format == 'channels_first':\n",
        "            outputs = K.permute_dimensions(outputs, (0, 1, 2))\n",
        "\n",
        "        if self.use_bias:\n",
        "            outputs = nn.bias_add(outputs, self.bias, data_format=data_format)\n",
        "\n",
        "        if self.activation is not None:\n",
        "            outputs = self.activation(outputs)\n",
        "        return outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.data_format == 'channels_last':\n",
        "            space = input_shape[1:-1]\n",
        "            new_space = []\n",
        "            for i in range(len(space)):\n",
        "                new_dim = conv_utils.conv_output_length(\n",
        "                    space[i],\n",
        "                    self.kernel_size[i],\n",
        "                    padding=self.padding,\n",
        "                    stride=self.strides[i],\n",
        "                    dilation=self.dilation_rate[i])\n",
        "                new_space.append(new_dim)\n",
        "            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n",
        "        if self.data_format == 'channels_first':\n",
        "            space = input_shape[2:]\n",
        "            new_space = []\n",
        "            for i in range(len(space)):\n",
        "                new_dim = conv_utils.conv_output_length(\n",
        "                    space[i],\n",
        "                    self.kernel_size[i],\n",
        "                    padding=self.padding,\n",
        "                    stride=self.strides[i],\n",
        "                    dilation=self.dilation_rate[i])\n",
        "                new_space.append(new_dim)\n",
        "            return (input_shape[0], self.filters) + tuple(new_space)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'filters': self.filters,\n",
        "            'kernel_size': self.kernel_size,\n",
        "            'kernel_function': {\n",
        "                'class_name': self.kernel_function.__class__.__name__,\n",
        "                'config': self.kernel_function.get_config(),\n",
        "            },\n",
        "            'strides': self.strides,\n",
        "            'padding': self.padding,\n",
        "            'data_format': self.data_format,\n",
        "            'dilation_rate': self.dilation_rate,\n",
        "            'activation': activations.serialize(self.activation),\n",
        "            'use_bias': self.use_bias,\n",
        "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
        "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
        "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
        "            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "            'bias_constraint': constraints.serialize(self.bias_constraint)\n",
        "        }\n",
        "        base_config = super(KernelConv2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config, custom_objects=None):\n",
        "        config['kernel_function'] = deserialize(\n",
        "            config.pop('kernel_function'),\n",
        "            custom_objects=custom_objects,\n",
        "        )\n",
        "        return cls(**config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o3jGnBtDYqY"
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential,Model\n",
        "from tensorflow.python.keras.layers import Flatten, Dense,AveragePooling1D,GRU,Convolution1D, MaxPooling1D, AveragePooling1D,Embedding,Input, Dense, Dropout, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM1TnqPBDfhs"
      },
      "source": [
        "class GaussianKernel(Layer):\n",
        "\n",
        "    def __init__(self, gamma, **kwargs):\n",
        "        super(GaussianKernel, self).__init__(**kwargs)\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        x, kernel = K.expand_dims(inputs[0], axis=-1), inputs[1]\n",
        "        return K.exp(-self.gamma * K.sum(K.square(x - kernel), axis=-2))\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'gamma': self.gamma}\n",
        "        base_config = super(GaussianKernel, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "class PolynomialKernel(Layer):\n",
        "\n",
        "    def __init__(self, p,\n",
        "                 c=0.0,\n",
        "                 trainable_c=False,\n",
        "                 initializer='zeros',\n",
        "                 regularizer=None,\n",
        "                 constraint=None,\n",
        "                 **kwargs):\n",
        "        super(PolynomialKernel, self).__init__(**kwargs)\n",
        "        self.p = p\n",
        "        self.c = c\n",
        "        self.oc = c\n",
        "        self.trainable_c = trainable_c\n",
        "        self.initializer = initializers.get(initializer)\n",
        "        self.regularizer = regularizers.get(regularizer)\n",
        "        self.constraint = constraints.get(constraint)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.trainable_c:\n",
        "            self.c = self.add_weight(\n",
        "                shape=(),\n",
        "                initializer=self.initializer,\n",
        "                regularizer=self.regularizer,\n",
        "                constraint=self.constraint,\n",
        "                name='{}_c'.format(self.name),\n",
        "            )\n",
        "        super(PolynomialKernel, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return (K.dot(inputs[0], inputs[1]) + self.c) ** self.p\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'p': self.p,\n",
        "            'c': self.oc,\n",
        "            'trainable_c': self.trainable_c,\n",
        "            'initializer': initializers.serialize(self.initializer),\n",
        "            'regularizer': regularizers.serialize(self.regularizer),\n",
        "            'constraint': initializers.serialize(self.constraint),\n",
        "        }\n",
        "        base_config = super(PolynomialKernel, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0kOlknKEa3Z"
      },
      "source": [
        "import pandas as pd\n",
        "dataset=pd.read_csv('New_Created_Data/100_tweets_per_user_new.csv')\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mtsPgOMEoi_"
      },
      "source": [
        "k=0\n",
        "X_train=[]\n",
        "y_train=[]\n",
        "for i in range(0,50):\n",
        "  for j in range(k,k+45):\n",
        "    X_train.append(dataset.iloc[j,0])\n",
        "    y_train.append(dataset.iloc[j,1])\n",
        "  k+=100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKKHJUTgEsrk"
      },
      "source": [
        "k=45\n",
        "X_test=[]\n",
        "y_test=[]\n",
        "for i in range(0,50):\n",
        "  for j in range(k,k+5):\n",
        "    X_test.append(dataset.iloc[j,0])\n",
        "    y_test.append(dataset.iloc[j,1])\n",
        "  k+=100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB_3MWErEyfn"
      },
      "source": [
        "X_train=pd.DataFrame(X_train)\n",
        "X_test=pd.DataFrame(X_test)\n",
        "y_train=pd.DataFrame(y_train)\n",
        "y_test=pd.DataFrame(y_test)\n",
        "X_train=X_train.iloc[:,:].values\n",
        "X_test=X_test.iloc[:,:].values\n",
        "y_train=y_train.iloc[:,:].values\n",
        "y_test=y_test.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKD4QWWAE2lj"
      },
      "source": [
        "train=np.concatenate((X_train,y_train),axis=1)\n",
        "test=np.concatenate((X_test,y_test),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asKupy6LE9AN"
      },
      "source": [
        "np.random.shuffle(train)\n",
        "np.random.shuffle(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45hY_uLlFBZj"
      },
      "source": [
        "train=pd.DataFrame(train)\n",
        "test=pd.DataFrame(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgQ5jX-kFGNO"
      },
      "source": [
        "X_train=train.iloc[:,0]\n",
        "X_test=test.iloc[:,0]\n",
        "y_train=train.iloc[:,1]\n",
        "y_test=test.iloc[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r5nAsGBFLR4"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_train)\n",
        "encoded_Y = encoder.transform(y_train)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "y_train = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySeO5tBfFRcW"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_test)\n",
        "encoded_Y = encoder.transform(y_test)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "y_test = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb9pSx4V-LLL"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(X_train)\n",
        "vectorizer.transform(X_train)\n",
        "vectorizer.transform(X_test)\n",
        "tfidf_vector_X = vectorizer.transform(X_train).toarray() \n",
        "tfidf_vector_Y = vectorizer.transform(X_test).toarray() \n",
        "tfidf_vector_X = tfidf_vector_X[:, :, None] \n",
        "tfidf_vector_Y = tfidf_vector_Y[:, :, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qntJOF-u-Ugk"
      },
      "source": [
        "a=tfidf_vector_X.shape[0]\n",
        "\n",
        "b=tfidf_vector_X.shape[1]\n",
        "tfidf_vector_X=tfidf_vector_X.reshape(a,1,b)\n",
        "tfidf_vector_Y=tfidf_vector_Y.reshape(tfidf_vector_Y.shape[0],1,b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UatoT2bDFuJZ"
      },
      "source": [
        "X_train = encode_data(X_train, maxlen, vocab, vocab_size, check)\n",
        "X_test= encode_data(X_test, maxlen, vocab, vocab_size, check)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kItFPr5GF3uV"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(X_train,y_train, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpXvxhn6F9Gz"
      },
      "source": [
        "gru_len = 128\n",
        "Routings = 5\n",
        "Num_capsule = 10\n",
        "Dim_capsule = 16\n",
        "dropout_p = 0.3\n",
        "rate_drop_dense = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFPYmKqeGHJJ"
      },
      "source": [
        "def squash(x, axis=-1):\n",
        "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
        "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
        "    return scale * x\n",
        "\n",
        "\n",
        "# define our own softmax function instead of K.softmax\n",
        "# because K.softmax can not specify axis.\n",
        "def softmax(x, axis=-1):\n",
        "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
        "    return ex / K.sum(ex, axis=axis, keepdims=True)\n",
        "\n",
        "\n",
        "# define the margin loss like hinge loss\n",
        "def margin_loss(y_true, y_pred):\n",
        "    lamb, margin = 0.5, 0.1\n",
        "    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
        "        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)\n",
        "\n",
        "\n",
        "class Capsule(Layer):\n",
        "    \"\"\"A Capsule Implement with Pure Keras\n",
        "    There are two vesions of Capsule.\n",
        "    One is like dense layer (for the fixed-shape input),\n",
        "    and the other is like timedistributed dense (for various length input).\n",
        "\n",
        "    The input shape of Capsule must be (batch_size,\n",
        "                                        input_num_capsule,\n",
        "                                        input_dim_capsule\n",
        "                                       )\n",
        "    and the output shape is (batch_size,\n",
        "                             num_capsule,\n",
        "                             dim_capsule\n",
        "                            )\n",
        "\n",
        "    Capsule Implement is from https://github.com/bojone/Capsule/\n",
        "    Capsule Paper: https://arxiv.org/abs/1710.09829\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_capsule,\n",
        "                 dim_capsule,\n",
        "                 routings=3,\n",
        "                 share_weights=True,\n",
        "                 activation='squash',\n",
        "                 **kwargs):\n",
        "        super(Capsule, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.share_weights = share_weights\n",
        "        if activation == 'squash':\n",
        "            self.activation = squash\n",
        "        else:\n",
        "            self.activation = activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim_capsule = input_shape[-1]\n",
        "        if self.share_weights:\n",
        "            self.kernel = self.add_weight(\n",
        "                name='capsule_kernel',\n",
        "                shape=(1, input_dim_capsule,\n",
        "                       self.num_capsule * self.dim_capsule),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "        else:\n",
        "            input_num_capsule = input_shape[-2]\n",
        "            self.kernel = self.add_weight(\n",
        "                name='capsule_kernel',\n",
        "                shape=(input_num_capsule, input_dim_capsule,\n",
        "                       self.num_capsule * self.dim_capsule),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Following the routing algorithm from Hinton's paper,\n",
        "        but replace b = b + <u,v> with b = <u,v>.\n",
        "\n",
        "        This change can improve the feature representation of Capsule.\n",
        "\n",
        "        However, you can replace\n",
        "            b = K.batch_dot(outputs, hat_inputs, [2, 3])\n",
        "        with\n",
        "            b += K.batch_dot(outputs, hat_inputs, [2, 3])\n",
        "        to realize a standard routing.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.share_weights:\n",
        "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
        "        else:\n",
        "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
        "\n",
        "        batch_size = K.shape(inputs)[0]\n",
        "        input_num_capsule = K.shape(inputs)[1]\n",
        "        hat_inputs = K.reshape(hat_inputs,\n",
        "                               (batch_size, input_num_capsule,\n",
        "                                self.num_capsule, self.dim_capsule))\n",
        "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
        "\n",
        "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
        "        for i in range(self.routings):\n",
        "            c = softmax(b, 1)\n",
        "            o = self.activation(K.batch_dot(c, hat_inputs, [2, 2]))\n",
        "            if i < self.routings - 1:\n",
        "                b = K.batch_dot(o, hat_inputs, [2, 3])\n",
        "                if K.backend() == 'theano':\n",
        "                    o = K.sum(o, axis=1)\n",
        "\n",
        "        return o\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (None, self.num_capsule, self.dim_capsule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEIhRLcbGP7J"
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3) \n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA_9n4b5GWi-"
      },
      "source": [
        "def model2(filter_kernels, dense_outputs, maxlen, vocab_size, nb_filter,cat_output):                                                  # For Character Embedding use this model instead of above model\n",
        "    d = 300                                                             #Embedding Size\n",
        "    inputs = Input(shape=(maxlen, vocab_size), name='input', dtype='float32')\n",
        "    #conv = Convolution1D(filters=nb_filter, kernel_size=filter_kernels[0], activation='relu',input_shape=(maxlen, vocab_size))(inputs)\n",
        "\n",
        "    conv=KernelConv2D(input_shape=(maxlen ,vocab_size),filters=128,kernel_size=1,kernel_function=PolynomialKernel(p=2, trainable_c=True))(inputs)\n",
        "    #conv = MaxPooling1D(pool_length=3)(conv)\n",
        "\n",
        "    conv1 = Convolution1D(filters=nb_filter, kernel_size=filter_kernels[1],\n",
        "                           activation='relu')(conv)\n",
        "    #conv1 = MaxPooling1D(pool_length=3)(conv1)\n",
        "\n",
        "    #conv2 = Convolution1D(nb_filter=nb_filter, filter_length=filter_kernels[2],border_mode='valid', activation='relu')(conv1)\n",
        "    #conv5 = MaxPooling1D(pool_length=3)(conv2)\n",
        "    conv6= Capsule(num_capsule=1 ,dim_capsule=72, routings=1,share_weights=True)(conv1)\n",
        "    conv = Flatten()(conv6)\n",
        "\n",
        "    #Two dense layers with dropout of .5\n",
        "    #z = Dropout(0.5)(Dense(dense_outputs, activation='relu')(conv))\n",
        "    # z = Dropout(0.5)(Dense(dense_outputs, activation='relu')(z))\n",
        "\n",
        "    pred = Dense(cat_output, activation='softmax', name='output')(conv)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=pred)\n",
        "\n",
        "    #sgd = SGD(lr=0.001, momentum=0.9)\n",
        "    #model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z38HdnatGbqt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "95d4e444-769e-4ff7-bdea-40b77647fccc"
      },
      "source": [
        "nb_filter = 500\n",
        "dense_outputs = 12\n",
        "filter_kernels = [1,1,1]\n",
        "cat_output = 50\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "model = model2(filter_kernels, dense_outputs,1,b, nb_filter, cat_output)\n",
        "model.summary()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 140, 70)]         0         \n",
            "_________________________________________________________________\n",
            "kernel_conv2d_5 (KernelConv2 (None, 140, 128)          9089      \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 137, 500)          256500    \n",
            "_________________________________________________________________\n",
            "capsule_5 (Capsule)          (None, 1, 1, 72)          36000     \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 72)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 2)                 146       \n",
            "=================================================================\n",
            "Total params: 301,735\n",
            "Trainable params: 301,735\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSj0tMm0GhP-"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt3IwycOGmh4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "76a6af50-3d9f-414b-ecce-07d6241063d5"
      },
      "source": [
        "model.fit(np.array(X_train), np.array(y_train),validation_data=(np.array(X_eval), np.array(y_eval)),batch_size=32,epochs=100, verbose=1,callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "46/46 [==============================] - 9s 185ms/step - loss: 0.1939 - accuracy: 0.9483 - val_loss: 0.2334 - val_accuracy: 0.9204\n",
            "Epoch 2/3\n",
            "46/46 [==============================] - 9s 186ms/step - loss: 0.1409 - accuracy: 0.9626 - val_loss: 0.1295 - val_accuracy: 0.9633\n",
            "Epoch 3/3\n",
            "46/46 [==============================] - 8s 184ms/step - loss: 0.1234 - accuracy: 0.9660 - val_loss: 0.1350 - val_accuracy: 0.9592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9df8ac84a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TesAxTJhIpnX"
      },
      "source": [
        "y_pred = model.predict(np.array(tfidf_vector_Y))\n",
        "\n",
        "y_pred=pd.DataFrame(y_pred)\n",
        "y_pred=y_pred.eq(y_pred.where(y_pred != 0).max(1), axis=0).astype(int)\n",
        "y_pred=y_pred.iloc[:,:].values\n",
        "\n",
        "y_test=pd.DataFrame(y_test)\n",
        "y_test=y_test.eq(y_test.where(y_test != 0).max(1), axis=0).astype(int)\n",
        "y_test=y_test.iloc[:,:].values\n",
        "\n",
        "result=[]\n",
        "for i in range(0,len(y_test)):\n",
        "  for j in range(0,len(y_test[0])):\n",
        "    if(y_test[i][j]==1):                                                                                                                                                                                                 result.append(j)\n",
        "\n",
        "predicted=[]\n",
        "for i in range(0,len(y_pred)):\n",
        "  for j in range(0,len(y_pred[0])):\n",
        "    if(y_pred[i][j]==1):\n",
        "      predicted.append(j)\n",
        "\n",
        "print(result)\n",
        "print(predicted)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(result,predicted)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "print('Confusion Matrix :')\n",
        "print(cm)\n",
        "print('Accuracy Score :',accuracy_score(result, predicted))\n",
        "print('Report : ')\n",
        "print(classification_report(result, predicted))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}