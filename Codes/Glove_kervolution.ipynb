{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Glove_kervolution.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MljNW85OD610"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets,transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from functools import partial\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gxJePHrEpIJ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.ops import nn\n",
        "from tensorflow.python.keras import activations, regularizers, initializers, constraints, engine\n",
        "from tensorflow.python.keras.utils import conv_utils\n",
        "from tensorflow.python.keras.layers import Layer, deserialize, Conv1D\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.ops import array_ops\n",
        "\n",
        "\n",
        "__all__ = ['KernelConv2D']\n",
        "\n",
        "\n",
        "class KernelConv2D(Layer):\n",
        "    \"\"\"2D convolution layer (e.g. spatial convolution over images).\n",
        "    This layer creates a convolution kernel that is convolved\n",
        "    with the layer input to produce a tensor of\n",
        "    outputs. If `use_bias` is True,\n",
        "    a bias vector is created and added to the outputs. Finally, if\n",
        "    `activation` is not `None`, it is applied to the outputs as well.\n",
        "    When using this layer as the first layer in a model,\n",
        "    provide the keyword argument `input_shape`\n",
        "    (tuple of integers, does not include the sample axis),\n",
        "    e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
        "    in `data_format=\"channels_last\"`.\n",
        "    # Arguments\n",
        "        filters: Integer, the dimensionality of the output space\n",
        "            (i.e. the number of output filters in the convolution).\n",
        "        kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
        "            height and width of the 2D convolution window.\n",
        "            Can be a single integer to specify the same value for\n",
        "            all spatial dimensions.\n",
        "        kernel_function: A layer takes the columnized feature and the kernel as its inputs.\n",
        "        strides: An integer or tuple/list of 2 integers,\n",
        "            specifying the strides of the convolution\n",
        "            along the height and width.\n",
        "            Can be a single integer to specify the same value for\n",
        "            all spatial dimensions.\n",
        "            Specifying any stride value != 1 is incompatible with specifying\n",
        "            any `dilation_rate` value != 1.\n",
        "        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
        "            Note that `\"same\"` is slightly inconsistent across backends with\n",
        "            `strides` != 1, as described\n",
        "            [here](https://github.com/keras-team/keras/pull/9473#issuecomment-372166860)\n",
        "        data_format: A string,\n",
        "            one of `\"channels_last\"` or `\"channels_first\"`.\n",
        "            The ordering of the dimensions in the inputs.\n",
        "            `\"channels_last\"` corresponds to inputs with shape\n",
        "            `(batch, height, width, channels)` while `\"channels_first\"`\n",
        "            corresponds to inputs with shape\n",
        "            `(batch, channels, height, width)`.\n",
        "            It defaults to the `image_data_format` value found in your\n",
        "            Keras config file at `~/.keras/keras.json`.\n",
        "            If you never set it, then it will be \"channels_last\".\n",
        "        dilation_rate: an integer or tuple/list of 2 integers, specifying\n",
        "            the dilation rate to use for dilated convolution.\n",
        "            Can be a single integer to specify the same value for\n",
        "            all spatial dimensions.\n",
        "            Currently, specifying any `dilation_rate` value != 1 is\n",
        "            incompatible with specifying any stride value != 1.\n",
        "        activation: Activation function to use\n",
        "            (see [activations](../activations.md)).\n",
        "            If you don't specify anything, no activation is applied\n",
        "            (ie. \"linear\" activation: `a(x) = x`).\n",
        "        use_bias: Boolean, whether the layer uses a bias vector.\n",
        "        kernel_initializer: Initializer for the `kernel` weights matrix.\n",
        "        bias_initializer: Initializer for the bias vector.\n",
        "        kernel_regularizer: Regularizer function applied to\n",
        "            the `kernel` weights matrix.\n",
        "        bias_regularizer: Regularizer function applied to the bias vector.\n",
        "        activity_regularizer: Regularizer function applied to\n",
        "            the output of the layer (its \"activation\").\n",
        "        kernel_constraint: Constraint function applied to the kernel matrix.\n",
        "        bias_constraint: Constraint function applied to the bias vector.\n",
        "    # Input shape\n",
        "        4D tensor with shape:\n",
        "        `(batch, channels, rows, cols)`\n",
        "        if `data_format` is `\"channels_first\"`\n",
        "        or 4D tensor with shape:\n",
        "        `(batch, rows, cols, channels)`\n",
        "        if `data_format` is `\"channels_last\"`.\n",
        "    # Output shape\n",
        "        4D tensor with shape:\n",
        "        `(batch, filters, new_rows, new_cols)`\n",
        "        if `data_format` is `\"channels_first\"`\n",
        "        or 4D tensor with shape:\n",
        "        `(batch, new_rows, new_cols, filters)`\n",
        "        if `data_format` is `\"channels_last\"`.\n",
        "        `rows` and `cols` values might have changed due to padding.\n",
        "    \"\"\"\n",
        "    def __init__(self, filters,\n",
        "                 kernel_size,\n",
        "                 kernel_function,\n",
        "                 strides=1,\n",
        "                 padding='valid',\n",
        "                 data_format=None,\n",
        "                 dilation_rate=1,\n",
        "                 activation=None,\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 **kwargs):\n",
        "        super(KernelConv2D, self).__init__(**kwargs)\n",
        "        self.rank = 1\n",
        "        self.filters = filters\n",
        "        self.kernel_function = kernel_function\n",
        "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, self.rank, 'kernel_size')\n",
        "        self.strides = conv_utils.normalize_tuple(strides, self.rank, 'strides')\n",
        "        self.padding = conv_utils.normalize_padding(padding)\n",
        "        self.data_format = conv_utils.normalize_data_format(data_format)\n",
        "        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, self.rank, 'dilation_rate')\n",
        "        self.activation = activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "        self.input_spec = engine.base_layer.InputSpec(ndim=self.rank + 2)\n",
        "\n",
        "        self.kernel = self.bias = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "        if input_shape.dims[channel_axis].value is None:\n",
        "            raise ValueError('The channel dimension of the inputs should be defined. Found `None`.')\n",
        "        input_dim = int(input_shape[channel_axis])\n",
        "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=kernel_shape,\n",
        "            initializer=self.kernel_initializer,\n",
        "            name='kernel',\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "        )\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "                shape=(self.filters,),\n",
        "                initializer=self.bias_initializer,\n",
        "                name='bias',\n",
        "                regularizer=self.bias_regularizer,\n",
        "                constraint=self.bias_constraint,\n",
        "            )\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "        self.input_spec = engine.base_layer.InputSpec(\n",
        "            ndim=self.rank + 2,\n",
        "            axes={channel_axis: input_dim},\n",
        "        )\n",
        "        self.kernel_function.build([input_shape, kernel_shape])\n",
        "        super(KernelConv2D, self).build(input_shape)\n",
        "\n",
        "    def _compute_causal_padding(self):\n",
        "      left_pad = self.dilation_rate[0] * (self.kernel_size[0] - 1)\n",
        "      if self.data_format == 'channels_last':\n",
        "        causal_padding = [[0, 0], [left_pad, 0], [0, 0]]\n",
        "      else:\n",
        "        causal_padding = [[0, 0], [0, 0], [left_pad, 0]]\n",
        "      return causal_padding\n",
        "\n",
        "    def call(self, inputs):\n",
        "        data_format = conv_utils.convert_data_format(self.data_format, self.rank + 2)\n",
        "        inputs, tf_data_format = K._preprocess_conv2d_input(inputs, self.data_format)\n",
        "\n",
        "        '''inputs = tf.compat.v1.extract_image_patches(\n",
        "            inputs,\n",
        "            ksizes=(1,) + K.int_shape(self.kernel)[:2] + (1,),\n",
        "            strides=(1,) + self.strides + (1,) + (1,) ,\n",
        "            rates=(1,) + self.dilation_rate + (1,) + (1,),\n",
        "            padding=self.padding.upper(),\n",
        "        )'''\n",
        "        inputs = array_ops.pad(inputs, self._compute_causal_padding())\n",
        "\n",
        "        kernel = K.reshape(self.kernel, (-1, self.filters))\n",
        "        outputs = self.kernel_function([inputs, kernel])\n",
        "\n",
        "        if self.data_format == 'channels_first':\n",
        "            outputs = K.permute_dimensions(outputs, (0, 1, 2))\n",
        "\n",
        "        if self.use_bias:\n",
        "            outputs = nn.bias_add(outputs, self.bias, data_format=data_format)\n",
        "\n",
        "        if self.activation is not None:\n",
        "            outputs = self.activation(outputs)\n",
        "        return outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.data_format == 'channels_last':\n",
        "            space = input_shape[1:-1]\n",
        "            new_space = []\n",
        "            for i in range(len(space)):\n",
        "                new_dim = conv_utils.conv_output_length(\n",
        "                    space[i],\n",
        "                    self.kernel_size[i],\n",
        "                    padding=self.padding,\n",
        "                    stride=self.strides[i],\n",
        "                    dilation=self.dilation_rate[i])\n",
        "                new_space.append(new_dim)\n",
        "            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n",
        "        if self.data_format == 'channels_first':\n",
        "            space = input_shape[2:]\n",
        "            new_space = []\n",
        "            for i in range(len(space)):\n",
        "                new_dim = conv_utils.conv_output_length(\n",
        "                    space[i],\n",
        "                    self.kernel_size[i],\n",
        "                    padding=self.padding,\n",
        "                    stride=self.strides[i],\n",
        "                    dilation=self.dilation_rate[i])\n",
        "                new_space.append(new_dim)\n",
        "            return (input_shape[0], self.filters) + tuple(new_space)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'filters': self.filters,\n",
        "            'kernel_size': self.kernel_size,\n",
        "            'kernel_function': {\n",
        "                'class_name': self.kernel_function.__class__.__name__,\n",
        "                'config': self.kernel_function.get_config(),\n",
        "            },\n",
        "            'strides': self.strides,\n",
        "            'padding': self.padding,\n",
        "            'data_format': self.data_format,\n",
        "            'dilation_rate': self.dilation_rate,\n",
        "            'activation': activations.serialize(self.activation),\n",
        "            'use_bias': self.use_bias,\n",
        "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
        "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
        "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
        "            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "            'bias_constraint': constraints.serialize(self.bias_constraint)\n",
        "        }\n",
        "        base_config = super(KernelConv2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config, custom_objects=None):\n",
        "        config['kernel_function'] = deserialize(\n",
        "            config.pop('kernel_function'),\n",
        "            custom_objects=custom_objects,\n",
        "        )\n",
        "        return cls(**config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD_DPETuE9Tr"
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential,Model\n",
        "from tensorflow.python.keras.layers import Flatten, Dense,AveragePooling1D,GRU,Convolution1D, MaxPooling1D, AveragePooling1D,Embedding,Input, Dense, Dropout, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bdRBD6iFDia"
      },
      "source": [
        "class GaussianKernel(Layer):\n",
        "\n",
        "    def __init__(self, gamma, **kwargs):\n",
        "        super(GaussianKernel, self).__init__(**kwargs)\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        x, kernel = K.expand_dims(inputs[0], axis=-1), inputs[1]\n",
        "        return K.exp(-self.gamma * K.sum(K.square(x - kernel), axis=-2))\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'gamma': self.gamma}\n",
        "        base_config = super(GaussianKernel, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "class PolynomialKernel(Layer):\n",
        "\n",
        "    def __init__(self, p,\n",
        "                 c=0.0,\n",
        "                 trainable_c=False,\n",
        "                 initializer='zeros',\n",
        "                 regularizer=None,\n",
        "                 constraint=None,\n",
        "                 **kwargs):\n",
        "        super(PolynomialKernel, self).__init__(**kwargs)\n",
        "        self.p = p\n",
        "        self.c = c\n",
        "        self.oc = c\n",
        "        self.trainable_c = trainable_c\n",
        "        self.initializer = initializers.get(initializer)\n",
        "        self.regularizer = regularizers.get(regularizer)\n",
        "        self.constraint = constraints.get(constraint)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.trainable_c:\n",
        "            self.c = self.add_weight(\n",
        "                shape=(),\n",
        "                initializer=self.initializer,\n",
        "                regularizer=self.regularizer,\n",
        "                constraint=self.constraint,\n",
        "                name='{}_c'.format(self.name),\n",
        "            )\n",
        "        super(PolynomialKernel, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return (K.dot(inputs[0], inputs[1]) + self.c) ** self.p\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'p': self.p,\n",
        "            'c': self.oc,\n",
        "            'trainable_c': self.trainable_c,\n",
        "            'initializer': initializers.serialize(self.initializer),\n",
        "            'regularizer': regularizers.serialize(self.regularizer),\n",
        "            'constraint': initializers.serialize(self.constraint),\n",
        "        }\n",
        "        base_config = super(PolynomialKernel, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmUir6s_HDw-"
      },
      "source": [
        "def squash(x, axis=-1):\n",
        "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
        "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
        "    return scale * x\n",
        "\n",
        "\n",
        "# define our own softmax function instead of K.softmax\n",
        "# because K.softmax can not specify axis.\n",
        "def softmax(x, axis=-1):\n",
        "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
        "    return ex / K.sum(ex, axis=axis, keepdims=True)\n",
        "\n",
        "\n",
        "# define the margin loss like hinge loss\n",
        "def margin_loss(y_true, y_pred):\n",
        "    lamb, margin = 0.5, 0.1\n",
        "    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
        "        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)\n",
        "\n",
        "\n",
        "class Capsule(Layer):\n",
        "    \"\"\"A Capsule Implement with Pure Keras\n",
        "    There are two vesions of Capsule.\n",
        "    One is like dense layer (for the fixed-shape input),\n",
        "    and the other is like timedistributed dense (for various length input).\n",
        "\n",
        "    The input shape of Capsule must be (batch_size,\n",
        "                                        input_num_capsule,\n",
        "                                        input_dim_capsule\n",
        "                                       )\n",
        "    and the output shape is (batch_size,\n",
        "                             num_capsule,\n",
        "                             dim_capsule\n",
        "                            )\n",
        "\n",
        "    Capsule Implement is from https://github.com/bojone/Capsule/\n",
        "    Capsule Paper: https://arxiv.org/abs/1710.09829\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_capsule,\n",
        "                 dim_capsule,\n",
        "                 routings=3,\n",
        "                 share_weights=True,\n",
        "                 activation='squash',\n",
        "                 **kwargs):\n",
        "        super(Capsule, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.share_weights = share_weights\n",
        "        if activation == 'squash':\n",
        "            self.activation = squash\n",
        "        else:\n",
        "            self.activation = activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim_capsule = input_shape[-1]\n",
        "        if self.share_weights:\n",
        "            self.kernel = self.add_weight(\n",
        "                name='capsule_kernel',\n",
        "                shape=(1, input_dim_capsule,\n",
        "                       self.num_capsule * self.dim_capsule),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "        else:\n",
        "            input_num_capsule = input_shape[-2]\n",
        "            self.kernel = self.add_weight(\n",
        "                name='capsule_kernel',\n",
        "                shape=(input_num_capsule, input_dim_capsule,\n",
        "                       self.num_capsule * self.dim_capsule),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Following the routing algorithm from Hinton's paper,\n",
        "        but replace b = b + <u,v> with b = <u,v>.\n",
        "\n",
        "        This change can improve the feature representation of Capsule.\n",
        "\n",
        "        However, you can replace\n",
        "            b = K.batch_dot(outputs, hat_inputs, [2, 3])\n",
        "        with\n",
        "            b += K.batch_dot(outputs, hat_inputs, [2, 3])\n",
        "        to realize a standard routing.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.share_weights:\n",
        "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
        "        else:\n",
        "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
        "\n",
        "        batch_size = K.shape(inputs)[0]\n",
        "        input_num_capsule = K.shape(inputs)[1]\n",
        "        hat_inputs = K.reshape(hat_inputs,\n",
        "                               (batch_size, input_num_capsule,\n",
        "                                self.num_capsule, self.dim_capsule))\n",
        "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
        "\n",
        "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
        "        for i in range(self.routings):\n",
        "            c = softmax(b, 1)\n",
        "            o = self.activation(K.batch_dot(c, hat_inputs, [2, 2]))\n",
        "            if i < self.routings - 1:\n",
        "                b = K.batch_dot(o, hat_inputs, [2, 3])\n",
        "                if K.backend() == 'theano':\n",
        "                    o = K.sum(o, axis=1)\n",
        "\n",
        "        return o\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (None, self.num_capsule, self.dim_capsule)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjoxZPVtFL0f"
      },
      "source": [
        "import pandas as pd\n",
        " \n",
        "dataset=pd.read_csv('/content/100_tweets_per_user_new.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_BKQF-oFQYW"
      },
      "source": [
        "k=0\n",
        "X_train=[]\n",
        "y_train=[]\n",
        "for i in range(0,50):\n",
        "  for j in range(k,k+90):\n",
        "    X_train.append(dataset.iloc[j,0])\n",
        "    y_train.append(dataset.iloc[j,1])\n",
        "  k+=100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55ElG1mGFgGd"
      },
      "source": [
        "k=90\n",
        "X_test=[]\n",
        "y_test=[]\n",
        "for i in range(0,50):\n",
        "  for j in range(k,k+10):\n",
        "    X_test.append(dataset.iloc[j,0])\n",
        "    y_test.append(dataset.iloc[j,1])\n",
        "  k+=100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCMEqplDFi8J"
      },
      "source": [
        "X_train=pd.DataFrame(X_train)\n",
        "X_test=pd.DataFrame(X_test)\n",
        "y_train=pd.DataFrame(y_train)\n",
        "y_test=pd.DataFrame(y_test)\n",
        "X_train=X_train.iloc[:,:].values\n",
        "X_test=X_test.iloc[:,:].values\n",
        "y_train=y_train.iloc[:,:].values\n",
        "y_test=y_test.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2NqwpViFmix"
      },
      "source": [
        "train=np.concatenate((X_train,y_train),axis=1)\n",
        "test=np.concatenate((X_test,y_test),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnnbZCSaFqLz"
      },
      "source": [
        "np.random.shuffle(train)\n",
        "np.random.shuffle(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRw3NYDQFtr2"
      },
      "source": [
        "train=pd.DataFrame(train)\n",
        "test=pd.DataFrame(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YQchUhKFwUT"
      },
      "source": [
        "\n",
        "X_train=train.iloc[:,0]\n",
        "X_test=test.iloc[:,0]\n",
        "y_train=train.iloc[:,1]\n",
        "y_test=test.iloc[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apHx3zm8F20d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99b28483-5957-45b3-ab55-f5bd89c22f8c"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_train)\n",
        "encoded_Y = encoder.transform(y_train)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "y_train = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz18TT-CF6Th"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_test)\n",
        "encoded_Y = encoder.transform(y_test)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "y_test = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tirU15pcF9OV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "28c5131c-9748-4313-8369-53bccf31aa8a"
      },
      "source": [
        "!unzip \"/content/drive/My Drive/1835_3176_compressed_glove.6B.100d.txt.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/1835_3176_compressed_glove.6B.100d.txt.zip\n",
            "  inflating: glove.6B.100d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an0Rv4IkGtMm"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#Tokenize the sentences\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(list((X_train)))\n",
        "\n",
        "#converting text into integer sequences\n",
        "X_train  = tokenizer.texts_to_sequences(X_train) \n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "#padding to prepare sequences of same length\n",
        "X_train  = pad_sequences(X_train, maxlen=300)\n",
        "X_test = pad_sequences(X_test, maxlen=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShtHQZJDG0Kv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cad4ef70-b5af-4ebd-c658-7b46f1cf3d07"
      },
      "source": [
        "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
        "print(size_of_vocabulary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9DrA7fvG2wL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5cc9717b-5156-4092-ab81-09e9e124b614"
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open('/content/glove.6B.100d.txt')\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG3uAtybG5qC"
      },
      "source": [
        "embedding_matrix = np.zeros((size_of_vocabulary, 100))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D2HNI8KHAX3"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(X_train,y_train, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwHrin_SHU_d"
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3) \n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39tdw-7EHb0M"
      },
      "source": [
        "def model2(filter_kernels, dense_outputs, maxlen, vocab_size, nb_filter,cat_output):                                                  # For Character Embedding use this model instead of above model\n",
        "    d = 300                                                             #Embedding Size \n",
        "    inputs = Input(shape=(maxlen,), name='input', dtype='float32')\n",
        "    embed=Embedding(size_of_vocabulary,100,weights=[embedding_matrix],input_length=300,trainable=False)(inputs) \n",
        "    z = Dropout(0.25)(Dense(dense_outputs, activation='relu')(embed))\n",
        "    #conv = Convolution1D(nb_filter=nb_filter, filter_length=filter_kernels[0],border_mode='valid', activation='relu',input_shape=(maxlen, d))(z)\n",
        "\n",
        "    conv=KernelConv2D(input_shape=(maxlen , d),filters=128,kernel_size=1,kernel_function=PolynomialKernel(p=2, trainable_c=True))(z)\n",
        "    #conv = MaxPooling1D(pool_length=3)(conv)\n",
        "\n",
        "    conv1 = Convolution1D(filters=nb_filter, kernel_size=filter_kernels[1],\n",
        "                           activation='relu')(conv)\n",
        "    #conv1 = MaxPooling1D(pool_length=3)(conv1)\n",
        "\n",
        "    #conv2 = Convolution1D(nb_filter=nb_filter, filter_length=filter_kernels[2],border_mode='valid', activation='relu')(conv1)\n",
        "    #conv5 = MaxPooling1D(pool_length=3)(conv2)\n",
        "    conv6= Capsule(num_capsule=1 ,dim_capsule=72, routings=1,share_weights=True)(conv1)\n",
        "    conv = Flatten()(conv6)\n",
        "\n",
        "    #Two dense layers with dropout of .5\n",
        "    #z = Dropout(0.5)(Dense(dense_outputs, activation='relu')(conv))\n",
        "    # z = Dropout(0.5)(Dense(dense_outputs, activation='relu')(z))\n",
        "\n",
        "    pred = Dense(cat_output, activation='softmax', name='output')(conv)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=pred)\n",
        "\n",
        "    #sgd = SGD(lr=0.001, momentum=0.9)\n",
        "    #model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5aGZy7_H4z8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "664a56a4-c013-42ba-93ef-dd10ba741c8b"
      },
      "source": [
        "nb_filter = 500\n",
        "dense_outputs = 256\n",
        "filter_kernels = [3,4,5]\n",
        "cat_output = 50\n",
        "maxlen = 300\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "model = model2(filter_kernels, dense_outputs,maxlen, 5, nb_filter, cat_output)\n",
        "model.summary()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 300)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 300, 100)          1465700   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 300, 256)          25856     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 300, 256)          0         \n",
            "_________________________________________________________________\n",
            "kernel_conv2d (KernelConv2D) (None, 300, 128)          32897     \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 297, 500)          256500    \n",
            "_________________________________________________________________\n",
            "capsule (Capsule)            (None, 1, 1, 72)          36000     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 72)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 50)                3650      \n",
            "=================================================================\n",
            "Total params: 1,820,603\n",
            "Trainable params: 354,903\n",
            "Non-trainable params: 1,465,700\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU6eADYkH8CN"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr_GDcpVISJt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "outputId": "08c17ac4-a550-42fa-f24b-20dc549167ae"
      },
      "source": [
        "model.fit(np.array(X_train), np.array(y_train),validation_data=(np.array(X_eval), np.array(y_eval)),batch_size=32,epochs=100, verbose=1,callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "106/106 [==============================] - 50s 473ms/step - loss: 3.7444 - accuracy: 0.0794 - val_loss: 3.5402 - val_accuracy: 0.1849\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 49s 463ms/step - loss: 3.3471 - accuracy: 0.2951 - val_loss: 3.1792 - val_accuracy: 0.3698\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 49s 466ms/step - loss: 3.0488 - accuracy: 0.4243 - val_loss: 2.9353 - val_accuracy: 0.4178\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 49s 467ms/step - loss: 2.8043 - accuracy: 0.4696 - val_loss: 2.7321 - val_accuracy: 0.4542\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 50s 469ms/step - loss: 2.5841 - accuracy: 0.5046 - val_loss: 2.5533 - val_accuracy: 0.4658\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 50s 468ms/step - loss: 2.3868 - accuracy: 0.5363 - val_loss: 2.3776 - val_accuracy: 0.5013\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 50s 472ms/step - loss: 2.1978 - accuracy: 0.5713 - val_loss: 2.2609 - val_accuracy: 0.4924\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 50s 470ms/step - loss: 2.0279 - accuracy: 0.6015 - val_loss: 2.1240 - val_accuracy: 0.5111\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 50s 469ms/step - loss: 1.8760 - accuracy: 0.6281 - val_loss: 2.0441 - val_accuracy: 0.5147\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 50s 468ms/step - loss: 1.7395 - accuracy: 0.6542 - val_loss: 1.9790 - val_accuracy: 0.5102\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 50s 470ms/step - loss: 1.5983 - accuracy: 0.7025 - val_loss: 1.9319 - val_accuracy: 0.5307\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 50s 471ms/step - loss: 1.4773 - accuracy: 0.7327 - val_loss: 1.8796 - val_accuracy: 0.5324\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 50s 474ms/step - loss: 1.3591 - accuracy: 0.7561 - val_loss: 1.8174 - val_accuracy: 0.5316\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 50s 469ms/step - loss: 1.2326 - accuracy: 0.7961 - val_loss: 1.7929 - val_accuracy: 0.5342\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 50s 468ms/step - loss: 1.1226 - accuracy: 0.8305 - val_loss: 1.7756 - val_accuracy: 0.5351\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 50s 469ms/step - loss: 1.0124 - accuracy: 0.8581 - val_loss: 1.7983 - val_accuracy: 0.5209\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 50s 467ms/step - loss: 0.9026 - accuracy: 0.8942 - val_loss: 1.7747 - val_accuracy: 0.5404\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 50s 469ms/step - loss: 0.7971 - accuracy: 0.9117 - val_loss: 1.7107 - val_accuracy: 0.5538\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 49s 463ms/step - loss: 0.6902 - accuracy: 0.9473 - val_loss: 1.7679 - val_accuracy: 0.5467\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 50s 475ms/step - loss: 0.5938 - accuracy: 0.9621 - val_loss: 1.7568 - val_accuracy: 0.5467\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 50s 471ms/step - loss: 0.5116 - accuracy: 0.9763 - val_loss: 1.7502 - val_accuracy: 0.5449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f47000d30b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdgrvUsWIUZA"
      },
      "source": [
        "y_pred = model.predict(np.array(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7e51lFWIZdf"
      },
      "source": [
        "y_pred=pd.DataFrame(y_pred)\n",
        "y_pred=y_pred.eq(y_pred.where(y_pred != 0).max(1), axis=0).astype(int)\n",
        "y_pred=y_pred.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxJqUKqbIaL7"
      },
      "source": [
        "y_test=pd.DataFrame(y_test)\n",
        "y_test=y_test.eq(y_test.where(y_test != 0).max(1), axis=0).astype(int)\n",
        "y_test=y_test.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvNQrumJIbwH"
      },
      "source": [
        "result=[]\n",
        "for i in range(0,len(y_test)):\n",
        "  for j in range(0,len(y_test[0])):\n",
        "    if(y_test[i][j]==1):\n",
        "      result.append(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB4lmBqjIfcU"
      },
      "source": [
        "predicted=[]\n",
        "for i in range(0,len(y_pred)):\n",
        "  for j in range(0,len(y_pred[0])):\n",
        "    if(y_pred[i][j]==1):\n",
        "      predicted.append(j)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJasu6YnIlKz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "978394c5-3ed6-44f7-8771-1789afc8f593"
      },
      "source": [
        "print(result)\n",
        "print(predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18, 30, 24, 38, 1, 35, 16, 13, 12, 12, 44, 10, 8, 32, 10, 27, 15, 35, 49, 36, 21, 27, 26, 35, 40, 41, 23, 1, 45, 28, 23, 44, 31, 0, 43, 28, 37, 21, 18, 35, 14, 38, 6, 32, 5, 46, 19, 49, 26, 45, 42, 32, 13, 12, 0, 13, 30, 6, 20, 11, 35, 0, 37, 4, 13, 17, 47, 48, 24, 11, 44, 0, 26, 15, 15, 42, 31, 8, 11, 14, 32, 25, 7, 5, 29, 45, 40, 9, 41, 35, 45, 20, 31, 5, 9, 4, 3, 30, 36, 10, 3, 39, 28, 17, 23, 43, 2, 38, 45, 29, 3, 18, 26, 49, 8, 6, 48, 29, 17, 2, 9, 8, 14, 15, 1, 39, 9, 37, 37, 44, 0, 14, 30, 40, 5, 27, 28, 14, 28, 16, 40, 24, 49, 1, 8, 37, 16, 23, 10, 24, 11, 3, 0, 37, 0, 45, 5, 48, 1, 42, 6, 47, 37, 3, 25, 14, 43, 20, 4, 34, 25, 13, 9, 30, 11, 21, 35, 21, 42, 41, 5, 41, 47, 13, 42, 12, 9, 17, 23, 9, 46, 45, 20, 37, 43, 27, 15, 48, 43, 28, 38, 9, 28, 3, 18, 16, 49, 38, 46, 24, 40, 12, 1, 33, 26, 33, 11, 33, 23, 3, 15, 34, 18, 6, 37, 46, 29, 26, 16, 1, 18, 23, 11, 8, 21, 44, 10, 12, 2, 31, 29, 24, 40, 25, 26, 10, 41, 42, 25, 5, 44, 12, 5, 37, 39, 47, 33, 47, 30, 16, 34, 40, 22, 3, 29, 19, 24, 35, 39, 4, 34, 4, 49, 24, 35, 7, 27, 33, 43, 36, 21, 25, 46, 39, 46, 40, 22, 33, 15, 41, 31, 9, 36, 24, 41, 3, 19, 6, 23, 27, 47, 36, 0, 9, 30, 23, 19, 19, 42, 3, 36, 22, 12, 34, 17, 12, 5, 16, 16, 29, 26, 41, 11, 31, 18, 48, 23, 16, 22, 2, 38, 36, 39, 39, 2, 6, 38, 46, 7, 34, 2, 26, 20, 4, 33, 13, 48, 38, 36, 11, 46, 45, 18, 17, 7, 30, 48, 8, 43, 40, 49, 42, 1, 4, 27, 22, 13, 46, 19, 20, 7, 4, 17, 39, 5, 14, 25, 45, 17, 27, 27, 22, 2, 47, 4, 30, 2, 34, 39, 19, 15, 48, 20, 22, 32, 17, 12, 8, 6, 31, 7, 35, 40, 1, 32, 28, 2, 42, 45, 41, 8, 19, 48, 30, 22, 44, 49, 43, 14, 4, 49, 1, 20, 10, 36, 46, 44, 2, 29, 39, 18, 11, 33, 28, 22, 33, 44, 10, 32, 36, 25, 21, 8, 19, 31, 20, 48, 26, 0, 7, 43, 24, 21, 31, 44, 49, 32, 29, 13, 15, 7, 32, 0, 20, 7, 43, 13, 22, 32, 16, 21, 27, 38, 31, 47, 21, 6, 18, 10, 42, 17, 38, 47, 28, 14, 29, 15, 10, 34, 14, 47, 25, 33, 34, 34, 25, 19, 41, 6, 7]\n",
            "[11, 30, 6, 38, 1, 35, 42, 13, 12, 5, 44, 5, 24, 25, 10, 27, 16, 35, 49, 36, 24, 27, 26, 14, 40, 41, 23, 1, 45, 28, 40, 12, 31, 18, 43, 28, 37, 36, 18, 30, 19, 9, 6, 0, 18, 46, 28, 49, 21, 45, 42, 12, 13, 26, 20, 48, 41, 6, 20, 38, 35, 18, 37, 4, 22, 17, 47, 48, 24, 13, 14, 5, 9, 22, 3, 43, 31, 2, 26, 14, 32, 32, 29, 5, 29, 45, 40, 9, 41, 35, 45, 20, 31, 27, 36, 4, 3, 30, 41, 10, 15, 39, 28, 17, 23, 43, 2, 5, 45, 29, 16, 38, 43, 49, 36, 6, 48, 7, 17, 12, 9, 12, 34, 26, 1, 39, 36, 37, 28, 44, 37, 14, 30, 40, 5, 27, 28, 14, 28, 27, 8, 29, 49, 1, 32, 34, 8, 47, 5, 12, 43, 3, 25, 28, 18, 45, 47, 48, 1, 42, 6, 47, 37, 21, 25, 47, 0, 26, 4, 5, 42, 13, 19, 30, 18, 12, 35, 42, 42, 41, 5, 41, 14, 13, 42, 12, 36, 17, 34, 16, 46, 45, 0, 40, 8, 31, 42, 48, 26, 28, 11, 9, 28, 3, 11, 16, 49, 22, 46, 24, 40, 42, 1, 33, 5, 33, 3, 33, 23, 5, 16, 34, 2, 6, 37, 46, 26, 38, 29, 1, 40, 23, 15, 19, 15, 44, 5, 26, 18, 31, 29, 24, 40, 18, 26, 10, 5, 42, 0, 21, 44, 5, 2, 48, 39, 47, 33, 47, 30, 16, 34, 40, 20, 29, 29, 7, 12, 30, 39, 4, 34, 4, 49, 18, 35, 21, 0, 33, 43, 36, 7, 28, 46, 39, 46, 40, 5, 33, 26, 41, 31, 5, 0, 24, 41, 3, 19, 6, 23, 27, 47, 36, 32, 7, 30, 23, 19, 0, 26, 27, 36, 29, 24, 46, 17, 16, 5, 29, 16, 29, 18, 41, 18, 31, 25, 48, 23, 16, 2, 5, 29, 36, 34, 39, 8, 6, 29, 46, 2, 34, 5, 26, 27, 4, 33, 2, 48, 5, 36, 27, 46, 45, 5, 17, 21, 30, 48, 8, 5, 40, 49, 29, 1, 4, 22, 26, 13, 46, 40, 10, 18, 4, 17, 39, 11, 14, 5, 45, 17, 16, 11, 25, 20, 47, 4, 30, 32, 34, 39, 28, 5, 48, 14, 22, 34, 17, 20, 5, 34, 31, 20, 30, 40, 1, 2, 28, 25, 11, 45, 41, 8, 19, 48, 30, 11, 37, 49, 43, 22, 4, 49, 1, 5, 10, 36, 46, 44, 10, 29, 39, 18, 22, 33, 6, 2, 33, 44, 36, 0, 20, 27, 19, 8, 37, 31, 0, 48, 22, 24, 29, 11, 24, 0, 31, 41, 49, 17, 29, 13, 42, 42, 10, 5, 41, 7, 43, 13, 0, 25, 42, 29, 40, 2, 31, 47, 21, 6, 9, 19, 16, 17, 0, 47, 28, 14, 29, 16, 20, 40, 14, 47, 25, 33, 42, 34, 10, 20, 41, 6, 42]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX0o2d82Il30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "26b38cae-9905-47c9-c138-508f9e405ec0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(result,predicted)\n",
        "\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0, 10,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0,  1, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  9,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0, 10,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0, 10]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4l-TtJWIqUF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0d72fe26-2290-4471-d9b8-5a696489245e"
      },
      "source": [
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "print('Confusion Matrix :')\n",
        "print(cm) \n",
        "print('Accuracy Score :',accuracy_score(result, predicted)) \n",
        "print('Report : ')\n",
        "print(classification_report(result, predicted)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[ 0  0  0 ...  0  0  0]\n",
            " [ 0 10  0 ...  0  0  0]\n",
            " [ 0  0  1 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  9  0  0]\n",
            " [ 0  0  0 ...  0 10  0]\n",
            " [ 0  0  0 ...  0  0 10]]\n",
            "Accuracy Score : 0.544\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        10\n",
            "           1       1.00      1.00      1.00        10\n",
            "           2       0.10      0.10      0.10        10\n",
            "           3       0.67      0.40      0.50        10\n",
            "           4       1.00      1.00      1.00        10\n",
            "           5       0.15      0.40      0.22        10\n",
            "           6       0.82      0.90      0.86        10\n",
            "           7       0.20      0.10      0.13        10\n",
            "           8       0.43      0.30      0.35        10\n",
            "           9       0.50      0.30      0.37        10\n",
            "          10       0.50      0.40      0.44        10\n",
            "          11       0.00      0.00      0.00        10\n",
            "          12       0.22      0.20      0.21        10\n",
            "          13       0.88      0.70      0.78        10\n",
            "          14       0.60      0.60      0.60        10\n",
            "          15       0.00      0.00      0.00        10\n",
            "          16       0.33      0.40      0.36        10\n",
            "          17       0.91      1.00      0.95        10\n",
            "          18       0.15      0.20      0.17        10\n",
            "          19       0.38      0.30      0.33        10\n",
            "          20       0.20      0.20      0.20        10\n",
            "          21       0.17      0.10      0.12        10\n",
            "          22       0.12      0.10      0.11        10\n",
            "          23       1.00      0.70      0.82        10\n",
            "          24       0.56      0.50      0.53        10\n",
            "          25       0.25      0.20      0.22        10\n",
            "          26       0.23      0.30      0.26        10\n",
            "          27       0.40      0.40      0.40        10\n",
            "          28       0.64      0.90      0.75        10\n",
            "          29       0.42      0.80      0.55        10\n",
            "          30       0.75      0.90      0.82        10\n",
            "          31       0.91      1.00      0.95        10\n",
            "          32       0.20      0.10      0.13        10\n",
            "          33       1.00      1.00      1.00        10\n",
            "          34       0.50      0.60      0.55        10\n",
            "          35       1.00      0.60      0.75        10\n",
            "          36       0.54      0.70      0.61        10\n",
            "          37       0.62      0.50      0.56        10\n",
            "          38       0.25      0.10      0.14        10\n",
            "          39       1.00      0.90      0.95        10\n",
            "          40       0.60      0.90      0.72        10\n",
            "          41       0.69      0.90      0.78        10\n",
            "          42       0.33      0.50      0.40        10\n",
            "          43       0.62      0.50      0.56        10\n",
            "          44       1.00      0.60      0.75        10\n",
            "          45       1.00      1.00      1.00        10\n",
            "          46       0.91      1.00      0.95        10\n",
            "          47       0.75      0.90      0.82        10\n",
            "          48       0.83      1.00      0.91        10\n",
            "          49       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           0.54       500\n",
            "   macro avg       0.55      0.54      0.53       500\n",
            "weighted avg       0.55      0.54      0.53       500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKh1pFytNSuW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}