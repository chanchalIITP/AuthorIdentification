{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e01b43bb973e4dcf9c5bddf4fb7e19fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a3e3e3ef88bc43e79a323e27ed30e1ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2f96cca0d0be4ad4aa218cca9ef62733",
              "IPY_MODEL_c3b8d35151ab4017a9f1b68e9cab1272"
            ]
          }
        },
        "a3e3e3ef88bc43e79a323e27ed30e1ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f96cca0d0be4ad4aa218cca9ef62733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e74cd090b1f742709a05303b627827fc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33d569a867a84a019dd3acb6e0b600af"
          }
        },
        "c3b8d35151ab4017a9f1b68e9cab1272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9cdaa0aa27424db5848b1d1566c48832",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.62MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dcb1736136b7437eb93acd9de1f04622"
          }
        },
        "e74cd090b1f742709a05303b627827fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33d569a867a84a019dd3acb6e0b600af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cdaa0aa27424db5848b1d1566c48832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dcb1736136b7437eb93acd9de1f04622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a4fc94227e54e4bb7c468cfa416d1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0c37327089f84d60950a7d979b4209c8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_647bd89d086245ecb1c4da6f38ee4575",
              "IPY_MODEL_03e58dc88c454c789ab7ef9b4c900dfa"
            ]
          }
        },
        "0c37327089f84d60950a7d979b4209c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "647bd89d086245ecb1c4da6f38ee4575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_84c79f0e637c467b84f3b8178a17ec91",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60b74cfd47d84f4bac8dafe424eea33b"
          }
        },
        "03e58dc88c454c789ab7ef9b4c900dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4642655be184bf6998f9b6540542c08",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:13&lt;00:00, 32.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f61016acddee4bc38c75fe4ab15cd871"
          }
        },
        "84c79f0e637c467b84f3b8178a17ec91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60b74cfd47d84f4bac8dafe424eea33b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4642655be184bf6998f9b6540542c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f61016acddee4bc38c75fe4ab15cd871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2befb22054ec46f1b08478b143b49c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d973bcf8f5bf4e5cb429192cf84debf5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aaf68360889f4f799665e9f2b1707dc0",
              "IPY_MODEL_d6b1f39212a9435e809f47fbe6e64223"
            ]
          }
        },
        "d973bcf8f5bf4e5cb429192cf84debf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aaf68360889f4f799665e9f2b1707dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4dc943115fb34090a7a44e1959281a0a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6acfe7bc94b3400b973bb46e4d9f2e9e"
          }
        },
        "d6b1f39212a9435e809f47fbe6e64223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b4f5dc123f23492e88003bd217b4c7c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:13&lt;00:00, 20.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_384b9ac0c3044131bc01d2cb467d6630"
          }
        },
        "4dc943115fb34090a7a44e1959281a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6acfe7bc94b3400b973bb46e4d9f2e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4f5dc123f23492e88003bd217b4c7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "384b9ac0c3044131bc01d2cb467d6630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r119exTOKGT1"
      },
      "source": [
        "**TEXT** **CLASSIFICATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjW3UOVANjV4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "382bd6d8-c1a5-47fd-c499-bf0c20c56ce8"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9lDmC00N6NG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ae6c290f-6f1d-4e03-e406-997dc46a8ee3"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gywd6seFAfT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "5a1ec147-af8a-48e5-fe25-00a29d87a795"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 15.1MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 19.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 42.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=4d97058a92fbc2c595a5dd582dcabb1ec191974fa7a1c373d4f87b4ec1f9442e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv1J2ltQA8nM"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers  as ppb \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VPaMZIwH2GL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "e01b43bb973e4dcf9c5bddf4fb7e19fa",
            "a3e3e3ef88bc43e79a323e27ed30e1ea",
            "2f96cca0d0be4ad4aa218cca9ef62733",
            "c3b8d35151ab4017a9f1b68e9cab1272",
            "e74cd090b1f742709a05303b627827fc",
            "33d569a867a84a019dd3acb6e0b600af",
            "9cdaa0aa27424db5848b1d1566c48832",
            "dcb1736136b7437eb93acd9de1f04622",
            "9a4fc94227e54e4bb7c468cfa416d1a8",
            "0c37327089f84d60950a7d979b4209c8",
            "647bd89d086245ecb1c4da6f38ee4575",
            "03e58dc88c454c789ab7ef9b4c900dfa",
            "84c79f0e637c467b84f3b8178a17ec91",
            "60b74cfd47d84f4bac8dafe424eea33b",
            "e4642655be184bf6998f9b6540542c08",
            "f61016acddee4bc38c75fe4ab15cd871",
            "2befb22054ec46f1b08478b143b49c83",
            "d973bcf8f5bf4e5cb429192cf84debf5",
            "aaf68360889f4f799665e9f2b1707dc0",
            "d6b1f39212a9435e809f47fbe6e64223",
            "4dc943115fb34090a7a44e1959281a0a",
            "6acfe7bc94b3400b973bb46e4d9f2e9e",
            "b4f5dc123f23492e88003bd217b4c7c2",
            "384b9ac0c3044131bc01d2cb467d6630"
          ]
        },
        "outputId": "1674e39b-0c2c-4fdf-8585-ee7175ee0740"
      },
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "#We can use BERT but here I am using DistillBERT because BERT requires more RAM then available in the colab,but to use BERT just uncomment the next line and comment the previous line\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)\n",
        "#To run the model on GPU\n",
        "#model.cuda()   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e01b43bb973e4dcf9c5bddf4fb7e19fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a4fc94227e54e4bb7c468cfa416d1a8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2befb22054ec46f1b08478b143b49c83",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=267967963.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSsGY0w3xn8X"
      },
      "source": [
        "In the Bert Tokenizer all the words are linked with ids and we can find those ids using Tokenizer It contains around 30,000 word and each related with ids and the mechanism that bert follows to get ids of unknown word is to break them into subwords and then find ids of each subword for eg:beddings will be break down into bed + ##dings except The first word  all are followed by ## token and even if the subwords are unknown it breaks into even characters!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6WRFw_zLA_f"
      },
      "source": [
        "#Importing the dataset\n",
        "import pandas as pd\n",
        " \n",
        "dataset=pd.read_csv('/content/50_tweets_per_user.csv')\n",
        "#dataset.iloc[:,0:1].fillna('other', inplace=True)\n",
        "y=dataset.iloc[:,1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJlbJrx46TI2"
      },
      "source": [
        "k=0\n",
        "X_train=[]\n",
        "y_train=[]\n",
        "for i in range(0,50):\n",
        "  for j in range(k,k+45):\n",
        "    X_train.append(dataset.iloc[j,0])\n",
        "    y_train.append(dataset.iloc[j,1])\n",
        "  k+=60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se1fAZ4H6VMM"
      },
      "source": [
        "k=45\n",
        "X_test=[]\n",
        "y_test=[]\n",
        "for i in range(0,50):\n",
        "  for j in range(k,k+5):\n",
        "    X_test.append(dataset.iloc[j,0])\n",
        "    y_test.append(dataset.iloc[j,1])\n",
        "  k+=60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC1DYlpC6VXn"
      },
      "source": [
        "X_train=pd.DataFrame(X_train)\n",
        "X_test=pd.DataFrame(X_test)\n",
        "y_train=pd.DataFrame(y_train)\n",
        "y_test=pd.DataFrame(y_test)\n",
        "X_train=X_train.iloc[:,:].values\n",
        "X_test=X_test.iloc[:,:].values\n",
        "y_train=y_train.iloc[:,:].values\n",
        "y_test=y_test.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9KSNKfaWbJk"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEAi6hZ06hge"
      },
      "source": [
        "train=np.concatenate((X_train,y_train),axis=1)\n",
        "test=np.concatenate((X_test,y_test),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jigPpgE16hrE"
      },
      "source": [
        "np.random.shuffle(train)\n",
        "np.random.shuffle(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Njd1QsbL6oCi"
      },
      "source": [
        "train=pd.DataFrame(train)\n",
        "test=pd.DataFrame(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNzcxbq16oPS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "81715ba9-9c4a-4f6b-c612-f78525e9d4d6"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHc6gVds6wch",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "2048b9fd-819e-4d75-e757-5569cffdbd3d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzYyP87Q60ov"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer() \n",
        "\n",
        "def preprocess(sentence):\n",
        "  sentence=str(sentence)\n",
        "  sentence = sentence.lower()\n",
        "  sentence=sentence.replace('{html}',\"\") \n",
        "  cleanr = re.compile('<.*?>#@')\n",
        "  cleantext = re.sub(cleanr, '', sentence)\n",
        "  rem_url=re.sub(r'http\\S+', '',cleantext)\n",
        "  rem_num = re.sub('[0-9]+', '', rem_url)\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(rem_num)  \n",
        "  filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "  stem_words=[stemmer.stem(w) for w in filtered_words]\n",
        "  lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
        "  return \" \".join(filtered_words)\n",
        "\n",
        "\n",
        "train.iloc[:,0]=train.iloc[:,0].map(lambda s:preprocess(s))\n",
        "test.iloc[:,0]=test.iloc[:,0].map(lambda s:preprocess(s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbuL7XTW68BJ"
      },
      "source": [
        "X_train=train.iloc[:,0]\n",
        "X_test=test.iloc[:,0]\n",
        "y_train=train.iloc[:,1]\n",
        "y_test=test.iloc[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsLUa3Q9AE4I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "560aa488-93f6-46e0-e7ee-1b7cb8bc8116"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2250,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3g-zCtY6UVl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec5ea6c0-b002-4392-a9e6-88837f6719c5"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_train)\n",
        "encoded_Y = encoder.transform(y_train)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "y_train = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjW3ABDR7MDe"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_test)\n",
        "encoded_Y = encoder.transform(y_test)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "y_test = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uP1Ecl77VMv"
      },
      "source": [
        "X_train=pd.DataFrame(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7lDNhvMdMjX"
      },
      "source": [
        "tokenized = X_train.iloc[:,0].apply((lambda x: tokenizer.encode(str(x), add_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTexBWhd3Owc"
      },
      "source": [
        "As BERT is a pretrained model We are required to:\n",
        "\n",
        "1. Add special tokens to the start and end of each sentence.\n",
        "2. Pad & truncate all sentences to a single constant length.\n",
        "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weru56XyhHE0"
      },
      "source": [
        "\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHcawiMreSH5"
      },
      "source": [
        "#for adding paddings\n",
        "input_ids = torch.tensor(np.array(padded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLuyjx_8hQsc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96c04eb5-206e-4670-c61d-296c11d7dd78"
      },
      "source": [
        "#to set the paddings to zero and rest to 1\n",
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2250, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5OQfo-5hecL"
      },
      "source": [
        "#To convert the parameters to torch tensors\n",
        "#input_ids = (torch.tensor(padded)).to(device)  \n",
        "#attention_mask = (torch.tensor(attention_mask)).to(device)\n",
        "input_ids = (torch.tensor(padded))\n",
        "attention_mask = (torch.tensor(attention_mask))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIpaEyWdjPxN"
      },
      "source": [
        "with torch.no_grad():\n",
        "    last_hidden_states_train = model(input_ids,attention_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjKVTR8gjWdk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39645477-7fdc-4435-9532-0272d4d69a7d"
      },
      "source": [
        "last_hidden_states_train[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2250, 36, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_8t5O3o4QCR"
      },
      "source": [
        "![Illustration of CLS token purpose](http://www.mccormickml.com/assets/BERT/CLS_token_500x606.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABOgg3I4kdbe"
      },
      "source": [
        "#Extracting the CLS only to feed into the classifier\n",
        "#features = last_hidden_states[0][:,0,:].cpu().numpy()\n",
        "\n",
        "X_train = last_hidden_states_train[0][:,0,:].numpy()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Vf33R-J6iC_"
      },
      "source": [
        "#Normalizing the input for fast execution\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range = (0, 1))\n",
        "X_train = sc.fit_transform(X_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gtbT197CE1V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b67f7a91-35ee-46ab-cba6-836b8880dbe1"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2250, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K09qjzEZ9EQ4"
      },
      "source": [
        "#LStm expects array of 3-dimension\n",
        "X_train = np.reshape(X_train, (2250,1,768))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlm7SJU7b_Jl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7b788d6-c671-4152-f1ee-39e1ea702464"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2250, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHOeq2hhbG0o"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(X_train,y_train, test_size = 0.05, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EqslYM9bHCQ"
      },
      "source": [
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvzs89JQ9vvZ"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSFHfU05GhjV"
      },
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "# Adding the first LSTM layer and some Dropout regularisation\n",
        "classifier.add(LSTM(units = 48, activation='sigmoid', input_shape = (1, 768),return_sequences = True))\n",
        "classifier.add(Dropout(0.2))\n",
        "classifier.add(LSTM(units = 25))\n",
        "classifier.add(Dropout(0.2))\n",
        "\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units =50,activation='softmax'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXBk6TQPGz1Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "867b3ab0-a532-4dcf-bdf1-df5400594c5c"
      },
      "source": [
        "# Compiling the RNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 1, 48)             156864    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 48)             0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 25)                7400      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 25)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                1300      \n",
            "=================================================================\n",
            "Total params: 165,564\n",
            "Trainable params: 165,564\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgaWTNbvG4bW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f411319-9263-4bb2-ac9f-6ddffd452601"
      },
      "source": [
        "classifier.fit(np.array(X_train),np.array(y_train),batch_size=128,epochs=50,validation_data=(np.array(X_eval),np.array(y_eval)),verbose=1,callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2137 samples, validate on 113 samples\n",
            "Epoch 1/50\n",
            "2137/2137 [==============================] - 3s 1ms/step - loss: 3.9156 - accuracy: 0.0182 - val_loss: 3.9177 - val_accuracy: 0.0088\n",
            "Epoch 2/50\n",
            "2137/2137 [==============================] - 0s 102us/step - loss: 3.9117 - accuracy: 0.0215 - val_loss: 3.9144 - val_accuracy: 0.0177\n",
            "Epoch 3/50\n",
            "2137/2137 [==============================] - 0s 103us/step - loss: 3.9106 - accuracy: 0.0215 - val_loss: 3.9146 - val_accuracy: 0.0088\n",
            "Epoch 4/50\n",
            "2137/2137 [==============================] - 0s 103us/step - loss: 3.9100 - accuracy: 0.0239 - val_loss: 3.9143 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "2137/2137 [==============================] - 0s 105us/step - loss: 3.9079 - accuracy: 0.0370 - val_loss: 3.9096 - val_accuracy: 0.0442\n",
            "Epoch 6/50\n",
            "2137/2137 [==============================] - 0s 102us/step - loss: 3.9040 - accuracy: 0.0328 - val_loss: 3.9125 - val_accuracy: 0.0177\n",
            "Epoch 7/50\n",
            "2137/2137 [==============================] - 0s 104us/step - loss: 3.8991 - accuracy: 0.0356 - val_loss: 3.9011 - val_accuracy: 0.0708\n",
            "Epoch 8/50\n",
            "2137/2137 [==============================] - 0s 106us/step - loss: 3.8875 - accuracy: 0.0398 - val_loss: 3.8976 - val_accuracy: 0.0265\n",
            "Epoch 9/50\n",
            "2137/2137 [==============================] - 0s 106us/step - loss: 3.8679 - accuracy: 0.0519 - val_loss: 3.8701 - val_accuracy: 0.0531\n",
            "Epoch 10/50\n",
            "2137/2137 [==============================] - 0s 105us/step - loss: 3.8385 - accuracy: 0.0566 - val_loss: 3.8464 - val_accuracy: 0.0708\n",
            "Epoch 11/50\n",
            "2137/2137 [==============================] - 0s 106us/step - loss: 3.8096 - accuracy: 0.0543 - val_loss: 3.8034 - val_accuracy: 0.0885\n",
            "Epoch 12/50\n",
            "2137/2137 [==============================] - 0s 104us/step - loss: 3.7603 - accuracy: 0.0669 - val_loss: 3.7784 - val_accuracy: 0.0619\n",
            "Epoch 13/50\n",
            "2137/2137 [==============================] - 0s 103us/step - loss: 3.7333 - accuracy: 0.0697 - val_loss: 3.7506 - val_accuracy: 0.0885\n",
            "Epoch 14/50\n",
            "2137/2137 [==============================] - 0s 106us/step - loss: 3.7080 - accuracy: 0.0679 - val_loss: 3.7538 - val_accuracy: 0.0531\n",
            "Epoch 15/50\n",
            "2137/2137 [==============================] - 0s 107us/step - loss: 3.6795 - accuracy: 0.0772 - val_loss: 3.7125 - val_accuracy: 0.0619\n",
            "Epoch 16/50\n",
            "2137/2137 [==============================] - 0s 104us/step - loss: 3.6541 - accuracy: 0.0739 - val_loss: 3.7193 - val_accuracy: 0.0708\n",
            "Epoch 17/50\n",
            "2137/2137 [==============================] - 0s 104us/step - loss: 3.6396 - accuracy: 0.0735 - val_loss: 3.6996 - val_accuracy: 0.0619\n",
            "Epoch 18/50\n",
            "2137/2137 [==============================] - 0s 102us/step - loss: 3.6190 - accuracy: 0.0828 - val_loss: 3.6578 - val_accuracy: 0.0973\n",
            "Epoch 19/50\n",
            "2137/2137 [==============================] - 0s 106us/step - loss: 3.5964 - accuracy: 0.0847 - val_loss: 3.6464 - val_accuracy: 0.0973\n",
            "Epoch 20/50\n",
            "2137/2137 [==============================] - 0s 107us/step - loss: 3.5768 - accuracy: 0.0894 - val_loss: 3.6341 - val_accuracy: 0.0973\n",
            "Epoch 21/50\n",
            "2137/2137 [==============================] - 0s 103us/step - loss: 3.5626 - accuracy: 0.0936 - val_loss: 3.6220 - val_accuracy: 0.0973\n",
            "Epoch 22/50\n",
            "2137/2137 [==============================] - 0s 105us/step - loss: 3.5602 - accuracy: 0.0936 - val_loss: 3.6144 - val_accuracy: 0.0973\n",
            "Epoch 23/50\n",
            "2137/2137 [==============================] - 0s 103us/step - loss: 3.5423 - accuracy: 0.0955 - val_loss: 3.5973 - val_accuracy: 0.1062\n",
            "Epoch 24/50\n",
            "2137/2137 [==============================] - 0s 102us/step - loss: 3.5291 - accuracy: 0.1020 - val_loss: 3.5797 - val_accuracy: 0.1062\n",
            "Epoch 25/50\n",
            "2137/2137 [==============================] - 0s 104us/step - loss: 3.5203 - accuracy: 0.0959 - val_loss: 3.5820 - val_accuracy: 0.0973\n",
            "Epoch 26/50\n",
            "2137/2137 [==============================] - 0s 105us/step - loss: 3.5090 - accuracy: 0.1123 - val_loss: 3.5635 - val_accuracy: 0.1150\n",
            "Epoch 27/50\n",
            "2137/2137 [==============================] - 0s 105us/step - loss: 3.4947 - accuracy: 0.1072 - val_loss: 3.6007 - val_accuracy: 0.0973\n",
            "Epoch 28/50\n",
            "2137/2137 [==============================] - 0s 108us/step - loss: 3.4788 - accuracy: 0.1104 - val_loss: 3.5579 - val_accuracy: 0.1062\n",
            "Epoch 29/50\n",
            "2137/2137 [==============================] - 0s 104us/step - loss: 3.4735 - accuracy: 0.1156 - val_loss: 3.5449 - val_accuracy: 0.1150\n",
            "Epoch 30/50\n",
            "2137/2137 [==============================] - 0s 106us/step - loss: 3.4556 - accuracy: 0.1203 - val_loss: 3.5258 - val_accuracy: 0.0973\n",
            "Epoch 31/50\n",
            "2137/2137 [==============================] - 0s 104us/step - loss: 3.4584 - accuracy: 0.1156 - val_loss: 3.5309 - val_accuracy: 0.1150\n",
            "Epoch 32/50\n",
            "2137/2137 [==============================] - 0s 101us/step - loss: 3.4350 - accuracy: 0.1170 - val_loss: 3.5149 - val_accuracy: 0.1062\n",
            "Epoch 33/50\n",
            "2137/2137 [==============================] - 0s 108us/step - loss: 3.4257 - accuracy: 0.1287 - val_loss: 3.5168 - val_accuracy: 0.0973\n",
            "Epoch 34/50\n",
            "2137/2137 [==============================] - 0s 105us/step - loss: 3.4334 - accuracy: 0.1203 - val_loss: 3.5176 - val_accuracy: 0.1062\n",
            "Epoch 35/50\n",
            "2137/2137 [==============================] - 0s 104us/step - loss: 3.4210 - accuracy: 0.1231 - val_loss: 3.5180 - val_accuracy: 0.1239\n",
            "Epoch 00035: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fec1c624908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEx8WgI2d3KM"
      },
      "source": [
        "X_test=pd.DataFrame(X_test)\n",
        "tokenized = X_test.iloc[:,0].apply((lambda x: tokenizer.encode(str(x), add_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cumrp4BHT-j"
      },
      "source": [
        "\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(36-len(i)) for i in tokenized.values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEJ5C0YuHkFK"
      },
      "source": [
        "#for adding paddings\n",
        "input_ids = torch.tensor(np.array(padded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPooGFE1Hroh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a695f16-42de-40ac-8f53-cbe97a90ff64"
      },
      "source": [
        "#to set the paddings to zero and rest to 1\n",
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250, 36)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wdw3RGGHx9P"
      },
      "source": [
        "#To convert the parameters to torch tensors\n",
        "#input_ids = (torch.tensor(padded)).to(device)  \n",
        "#attention_mask = (torch.tensor(attention_mask)).to(device)\n",
        "input_ids = (torch.tensor(padded))\n",
        "attention_mask = (torch.tensor(attention_mask))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukVPlng_H4Es"
      },
      "source": [
        "with torch.no_grad():\n",
        "    last_hidden_states_test = model(input_ids,attention_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BufbBqYE_b_N"
      },
      "source": [
        "X_test= last_hidden_states_test[0][:,0,:].numpy()\n",
        "X_test=sc.transform(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvrfQHMQg_Ne"
      },
      "source": [
        "X_test=np.reshape(X_test,(250,1,768))\n",
        "y_pred =  classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMuF4TV0_kxu"
      },
      "source": [
        "#TO get maximum value as 1 and rest to zero\n",
        "y_pred=pd.DataFrame(y_pred)\n",
        "y_pred=y_pred.eq(y_pred.where(y_pred != 0).max(1), axis=0).astype(int)\n",
        "y_pred=y_pred.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdKGvENq6Pqq"
      },
      "source": [
        "y_test=pd.DataFrame(y_test)\n",
        "y_test=y_test.eq(y_test.where(y_test != 0).max(1), axis=0).astype(int)\n",
        "y_test=y_test.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAIg3kbOsqb0"
      },
      "source": [
        "result=[]\n",
        "for i in range(0,len(y_test)):\n",
        "  for j in range(0,len(y_test[0])):\n",
        "    if(y_test[i][j]==1):\n",
        "      result.append(j)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3znJ1DEtZkb"
      },
      "source": [
        "predicted=[]\n",
        "for i in range(0,len(y_pred)):\n",
        "  for j in range(0,len(y_pred[0])):\n",
        "    if(y_pred[i][j]==1):\n",
        "      predicted.append(j)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF3asmMFuAfV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "903296da-dc0b-492f-8b1a-84ef5a467ee5"
      },
      "source": [
        "print(result)\n",
        "print(predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9, 14, 40, 19, 26, 14, 2, 37, 29, 11, 47, 48, 12, 36, 33, 37, 19, 12, 44, 3, 0, 27, 32, 20, 35, 28, 49, 19, 48, 0, 29, 44, 16, 36, 41, 15, 43, 21, 43, 2, 42, 34, 24, 35, 40, 37, 32, 39, 11, 49, 41, 22, 33, 39, 49, 41, 3, 15, 5, 12, 5, 47, 45, 22, 38, 46, 18, 0, 41, 39, 4, 13, 5, 30, 6, 20, 25, 23, 26, 42, 38, 47, 34, 8, 48, 34, 2, 18, 1, 17, 18, 46, 47, 7, 5, 13, 33, 20, 36, 17, 48, 7, 3, 26, 32, 44, 27, 45, 9, 38, 15, 42, 1, 6, 7, 15, 30, 14, 44, 28, 8, 22, 29, 6, 1, 32, 8, 43, 9, 4, 1, 13, 30, 30, 43, 44, 24, 25, 12, 7, 41, 11, 30, 36, 39, 37, 4, 49, 46, 46, 43, 35, 26, 40, 23, 16, 10, 17, 32, 40, 27, 24, 34, 28, 31, 48, 14, 17, 20, 6, 10, 1, 4, 9, 18, 0, 7, 2, 42, 46, 21, 27, 6, 22, 11, 18, 13, 15, 13, 20, 24, 25, 3, 45, 25, 45, 28, 34, 10, 23, 31, 21, 31, 23, 27, 31, 16, 38, 12, 16, 33, 29, 39, 35, 36, 33, 14, 17, 45, 19, 2, 5, 24, 42, 35, 23, 26, 21, 11, 19, 29, 9, 8, 8, 37, 10, 10, 4, 21, 40, 25, 31, 28, 38, 22, 3, 0, 16, 47, 49]\n",
            "[5, 14, 40, 9, 47, 13, 25, 25, 47, 5, 38, 42, 13, 8, 47, 9, 20, 5, 21, 9, 49, 9, 7, 8, 47, 40, 47, 47, 5, 0, 29, 47, 49, 47, 47, 47, 49, 21, 8, 21, 40, 47, 6, 40, 40, 5, 46, 46, 8, 43, 22, 43, 40, 12, 47, 40, 21, 0, 5, 21, 31, 43, 45, 38, 0, 46, 0, 0, 47, 38, 2, 25, 43, 38, 38, 5, 25, 5, 21, 5, 0, 47, 44, 2, 47, 40, 21, 9, 35, 40, 47, 0, 5, 5, 12, 5, 22, 6, 46, 46, 46, 0, 0, 45, 21, 45, 0, 18, 0, 9, 40, 42, 9, 0, 14, 47, 30, 47, 47, 40, 8, 5, 2, 8, 5, 40, 5, 47, 13, 20, 38, 21, 14, 9, 8, 27, 47, 25, 49, 47, 47, 40, 46, 7, 12, 9, 9, 46, 46, 0, 47, 0, 40, 47, 47, 47, 0, 47, 12, 40, 47, 13, 47, 40, 46, 47, 46, 49, 21, 47, 44, 40, 12, 2, 38, 0, 13, 21, 47, 0, 21, 38, 11, 46, 43, 47, 21, 12, 25, 9, 46, 25, 25, 45, 25, 13, 7, 47, 40, 7, 12, 21, 40, 46, 47, 43, 46, 46, 34, 5, 47, 14, 38, 0, 47, 40, 0, 6, 47, 47, 13, 5, 12, 44, 40, 47, 0, 21, 47, 47, 0, 21, 21, 8, 0, 14, 12, 13, 2, 40, 25, 5, 47, 43, 38, 47, 0, 0, 40, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVYQQ5K7laRQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "495f8cfd-78b2-445d-aa07-0bca41af2961"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(result,predicted)\n",
        "\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 2, 0, 0],\n",
              "       [0, 0, 0, ..., 2, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO4xPOZE-mJG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ab94b4f-31a5-4008-ef60-f993dfe790f9"
      },
      "source": [
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "print('Confusion Matrix :')\n",
        "print(cm) \n",
        "print('Accuracy Score :',accuracy_score(result, predicted)) \n",
        "print('Report : ')\n",
        "print(classification_report(result, predicted)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[4 0 0 ... 0 0 1]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 2 0 0]\n",
            " [0 0 0 ... 2 0 0]]\n",
            "Accuracy Score : 0.12\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.17      0.80      0.28         5\n",
            "           1       0.00      0.00      0.00         5\n",
            "           2       0.00      0.00      0.00         5\n",
            "           3       0.00      0.00      0.00         5\n",
            "           4       0.00      0.00      0.00         5\n",
            "           5       0.11      0.40      0.17         5\n",
            "           6       0.00      0.00      0.00         5\n",
            "           7       0.00      0.00      0.00         5\n",
            "           8       0.25      0.40      0.31         5\n",
            "           9       0.00      0.00      0.00         5\n",
            "          10       0.00      0.00      0.00         5\n",
            "          11       0.00      0.00      0.00         5\n",
            "          12       0.00      0.00      0.00         5\n",
            "          13       0.00      0.00      0.00         5\n",
            "          14       0.20      0.20      0.20         5\n",
            "          15       0.00      0.00      0.00         5\n",
            "          16       0.00      0.00      0.00         5\n",
            "          17       0.00      0.00      0.00         5\n",
            "          18       0.00      0.00      0.00         5\n",
            "          19       0.00      0.00      0.00         5\n",
            "          20       0.00      0.00      0.00         5\n",
            "          21       0.24      0.80      0.36         5\n",
            "          22       0.00      0.00      0.00         5\n",
            "          23       0.00      0.00      0.00         5\n",
            "          24       0.00      0.00      0.00         5\n",
            "          25       0.50      1.00      0.67         5\n",
            "          26       0.00      0.00      0.00         5\n",
            "          27       0.00      0.00      0.00         5\n",
            "          28       0.00      0.00      0.00         5\n",
            "          29       1.00      0.20      0.33         5\n",
            "          30       1.00      0.20      0.33         5\n",
            "          31       0.00      0.00      0.00         5\n",
            "          32       0.00      0.00      0.00         5\n",
            "          33       0.00      0.00      0.00         5\n",
            "          34       0.00      0.00      0.00         5\n",
            "          35       0.00      0.00      0.00         5\n",
            "          36       0.00      0.00      0.00         5\n",
            "          37       0.00      0.00      0.00         5\n",
            "          38       0.00      0.00      0.00         5\n",
            "          39       0.00      0.00      0.00         5\n",
            "          40       0.17      0.80      0.29         5\n",
            "          41       0.00      0.00      0.00         5\n",
            "          42       0.50      0.20      0.29         5\n",
            "          43       0.00      0.00      0.00         5\n",
            "          44       0.00      0.00      0.00         5\n",
            "          45       0.50      0.40      0.44         5\n",
            "          46       0.12      0.40      0.19         5\n",
            "          47       0.02      0.20      0.04         5\n",
            "          48       0.00      0.00      0.00         5\n",
            "          49       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.12       250\n",
            "   macro avg       0.10      0.12      0.08       250\n",
            "weighted avg       0.10      0.12      0.08       250\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bom4vHTFL_DW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}