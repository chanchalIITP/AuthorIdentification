{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Kervolution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgnpuI8KrjT4"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets,transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4dsKFSxrvCV"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.ops import nn\n",
        "from tensorflow.python.keras import activations, regularizers, initializers, constraints, engine\n",
        "from tensorflow.python.keras.utils import conv_utils\n",
        "from tensorflow.python.keras.layers import Layer, deserialize, Conv1D\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.ops import array_ops\n",
        "\n",
        "\n",
        "__all__ = ['KernelConv2D']\n",
        "\n",
        "\n",
        "class KernelConv2D(Layer):\n",
        "    \"\"\"2D convolution layer (e.g. spatial convolution over images).\n",
        "    This layer creates a convolution kernel that is convolved\n",
        "    with the layer input to produce a tensor of\n",
        "    outputs. If `use_bias` is True,\n",
        "    a bias vector is created and added to the outputs. Finally, if\n",
        "    `activation` is not `None`, it is applied to the outputs as well.\n",
        "    When using this layer as the first layer in a model,\n",
        "    provide the keyword argument `input_shape`\n",
        "    (tuple of integers, does not include the sample axis),\n",
        "    e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
        "    in `data_format=\"channels_last\"`.\n",
        "    # Arguments\n",
        "        filters: Integer, the dimensionality of the output space\n",
        "            (i.e. the number of output filters in the convolution).\n",
        "        kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
        "            height and width of the 2D convolution window.\n",
        "            Can be a single integer to specify the same value for\n",
        "            all spatial dimensions.\n",
        "        kernel_function: A layer takes the columnized feature and the kernel as its inputs.\n",
        "        strides: An integer or tuple/list of 2 integers,\n",
        "            specifying the strides of the convolution\n",
        "            along the height and width.\n",
        "            Can be a single integer to specify the same value for\n",
        "            all spatial dimensions.\n",
        "            Specifying any stride value != 1 is incompatible with specifying\n",
        "            any `dilation_rate` value != 1.\n",
        "        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
        "            Note that `\"same\"` is slightly inconsistent across backends with\n",
        "            `strides` != 1, as described\n",
        "            [here](https://github.com/keras-team/keras/pull/9473#issuecomment-372166860)\n",
        "        data_format: A string,\n",
        "            one of `\"channels_last\"` or `\"channels_first\"`.\n",
        "            The ordering of the dimensions in the inputs.\n",
        "            `\"channels_last\"` corresponds to inputs with shape\n",
        "            `(batch, height, width, channels)` while `\"channels_first\"`\n",
        "            corresponds to inputs with shape\n",
        "            `(batch, channels, height, width)`.\n",
        "            It defaults to the `image_data_format` value found in your\n",
        "            Keras config file at `~/.keras/keras.json`.\n",
        "            If you never set it, then it will be \"channels_last\".\n",
        "        dilation_rate: an integer or tuple/list of 2 integers, specifying\n",
        "            the dilation rate to use for dilated convolution.\n",
        "            Can be a single integer to specify the same value for\n",
        "            all spatial dimensions.\n",
        "            Currently, specifying any `dilation_rate` value != 1 is\n",
        "            incompatible with specifying any stride value != 1.\n",
        "        activation: Activation function to use\n",
        "            (see [activations](../activations.md)).\n",
        "            If you don't specify anything, no activation is applied\n",
        "            (ie. \"linear\" activation: `a(x) = x`).\n",
        "        use_bias: Boolean, whether the layer uses a bias vector.\n",
        "        kernel_initializer: Initializer for the `kernel` weights matrix.\n",
        "        bias_initializer: Initializer for the bias vector.\n",
        "        kernel_regularizer: Regularizer function applied to\n",
        "            the `kernel` weights matrix.\n",
        "        bias_regularizer: Regularizer function applied to the bias vector.\n",
        "        activity_regularizer: Regularizer function applied to\n",
        "            the output of the layer (its \"activation\").\n",
        "        kernel_constraint: Constraint function applied to the kernel matrix.\n",
        "        bias_constraint: Constraint function applied to the bias vector.\n",
        "    # Input shape\n",
        "        4D tensor with shape:\n",
        "        `(batch, channels, rows, cols)`\n",
        "        if `data_format` is `\"channels_first\"`\n",
        "        or 4D tensor with shape:\n",
        "        `(batch, rows, cols, channels)`\n",
        "        if `data_format` is `\"channels_last\"`.\n",
        "    # Output shape\n",
        "        4D tensor with shape:\n",
        "        `(batch, filters, new_rows, new_cols)`\n",
        "        if `data_format` is `\"channels_first\"`\n",
        "        or 4D tensor with shape:\n",
        "        `(batch, new_rows, new_cols, filters)`\n",
        "        if `data_format` is `\"channels_last\"`.\n",
        "        `rows` and `cols` values might have changed due to padding.\n",
        "    \"\"\"\n",
        "    def __init__(self, filters,\n",
        "                 kernel_size,\n",
        "                 kernel_function,\n",
        "                 strides=1,\n",
        "                 padding='valid',\n",
        "                 data_format=None,\n",
        "                 dilation_rate=1,\n",
        "                 activation=None,\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 **kwargs):\n",
        "        super(KernelConv2D, self).__init__(**kwargs)\n",
        "        self.rank = 1\n",
        "        self.filters = filters\n",
        "        self.kernel_function = kernel_function\n",
        "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, self.rank, 'kernel_size')\n",
        "        self.strides = conv_utils.normalize_tuple(strides, self.rank, 'strides')\n",
        "        self.padding = conv_utils.normalize_padding(padding)\n",
        "        self.data_format = conv_utils.normalize_data_format(data_format)\n",
        "        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, self.rank, 'dilation_rate')\n",
        "        self.activation = activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "        self.input_spec = engine.base_layer.InputSpec(ndim=self.rank + 2)\n",
        "\n",
        "        self.kernel = self.bias = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.data_format == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "        if input_shape.dims[channel_axis].value is None:\n",
        "            raise ValueError('The channel dimension of the inputs should be defined. Found `None`.')\n",
        "        input_dim = int(input_shape[channel_axis])\n",
        "        kernel_shape = self.kernel_size + (input_dim, self.filters)\n",
        "\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=kernel_shape,\n",
        "            initializer=self.kernel_initializer,\n",
        "            name='kernel',\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            constraint=self.kernel_constraint,\n",
        "        )\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "                shape=(self.filters,),\n",
        "                initializer=self.bias_initializer,\n",
        "                name='bias',\n",
        "                regularizer=self.bias_regularizer,\n",
        "                constraint=self.bias_constraint,\n",
        "            )\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "        self.input_spec = engine.base_layer.InputSpec(\n",
        "            ndim=self.rank + 2,\n",
        "            axes={channel_axis: input_dim},\n",
        "        )\n",
        "        self.kernel_function.build([input_shape, kernel_shape])\n",
        "        super(KernelConv2D, self).build(input_shape)\n",
        "\n",
        "    def _compute_causal_padding(self):\n",
        "      left_pad = self.dilation_rate[0] * (self.kernel_size[0] - 1)\n",
        "      if self.data_format == 'channels_last':\n",
        "        causal_padding = [[0, 0], [left_pad, 0], [0, 0]]\n",
        "      else:\n",
        "        causal_padding = [[0, 0], [0, 0], [left_pad, 0]]\n",
        "      return causal_padding\n",
        "\n",
        "    def call(self, inputs):\n",
        "        data_format = conv_utils.convert_data_format(self.data_format, self.rank + 2)\n",
        "        inputs, tf_data_format = K._preprocess_conv2d_input(inputs, self.data_format)\n",
        "\n",
        "        '''inputs = tf.compat.v1.extract_image_patches(\n",
        "            inputs,\n",
        "            ksizes=(1,) + K.int_shape(self.kernel)[:2] + (1,),\n",
        "            strides=(1,) + self.strides + (1,) + (1,) ,\n",
        "            rates=(1,) + self.dilation_rate + (1,) + (1,),\n",
        "            padding=self.padding.upper(),\n",
        "        )'''\n",
        "        inputs = array_ops.pad(inputs, self._compute_causal_padding())\n",
        "\n",
        "        kernel = K.reshape(self.kernel, (-1, self.filters))\n",
        "        outputs = self.kernel_function([inputs, kernel])\n",
        "\n",
        "        if self.data_format == 'channels_first':\n",
        "            outputs = K.permute_dimensions(outputs, (0, 1, 2))\n",
        "\n",
        "        if self.use_bias:\n",
        "            outputs = nn.bias_add(outputs, self.bias, data_format=data_format)\n",
        "\n",
        "        if self.activation is not None:\n",
        "            outputs = self.activation(outputs)\n",
        "        return outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.data_format == 'channels_last':\n",
        "            space = input_shape[1:-1]\n",
        "            new_space = []\n",
        "            for i in range(len(space)):\n",
        "                new_dim = conv_utils.conv_output_length(\n",
        "                    space[i],\n",
        "                    self.kernel_size[i],\n",
        "                    padding=self.padding,\n",
        "                    stride=self.strides[i],\n",
        "                    dilation=self.dilation_rate[i])\n",
        "                new_space.append(new_dim)\n",
        "            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n",
        "        if self.data_format == 'channels_first':\n",
        "            space = input_shape[2:]\n",
        "            new_space = []\n",
        "            for i in range(len(space)):\n",
        "                new_dim = conv_utils.conv_output_length(\n",
        "                    space[i],\n",
        "                    self.kernel_size[i],\n",
        "                    padding=self.padding,\n",
        "                    stride=self.strides[i],\n",
        "                    dilation=self.dilation_rate[i])\n",
        "                new_space.append(new_dim)\n",
        "            return (input_shape[0], self.filters) + tuple(new_space)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'filters': self.filters,\n",
        "            'kernel_size': self.kernel_size,\n",
        "            'kernel_function': {\n",
        "                'class_name': self.kernel_function.__class__.__name__,\n",
        "                'config': self.kernel_function.get_config(),\n",
        "            },\n",
        "            'strides': self.strides,\n",
        "            'padding': self.padding,\n",
        "            'data_format': self.data_format,\n",
        "            'dilation_rate': self.dilation_rate,\n",
        "            'activation': activations.serialize(self.activation),\n",
        "            'use_bias': self.use_bias,\n",
        "            'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
        "            'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
        "            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
        "            'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "            'bias_constraint': constraints.serialize(self.bias_constraint)\n",
        "        }\n",
        "        base_config = super(KernelConv2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config, custom_objects=None):\n",
        "        config['kernel_function'] = deserialize(\n",
        "            config.pop('kernel_function'),\n",
        "            custom_objects=custom_objects,\n",
        "        )\n",
        "        return cls(**config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv8cKxCQsIXw"
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Flatten, Dense,AveragePooling1D,GRU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC8vtF67s2Bv"
      },
      "source": [
        "class GaussianKernel(Layer):\n",
        "\n",
        "    def __init__(self, gamma, **kwargs):\n",
        "        super(GaussianKernel, self).__init__(**kwargs)\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        x, kernel = K.expand_dims(inputs[0], axis=-1), inputs[1]\n",
        "        return K.exp(-self.gamma * K.sum(K.square(x - kernel), axis=-2))\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'gamma': self.gamma}\n",
        "        base_config = super(GaussianKernel, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "class PolynomialKernel(Layer):\n",
        "\n",
        "    def __init__(self, p,\n",
        "                 c=0.0,\n",
        "                 trainable_c=False,\n",
        "                 initializer='zeros',\n",
        "                 regularizer=None,\n",
        "                 constraint=None,\n",
        "                 **kwargs):\n",
        "        super(PolynomialKernel, self).__init__(**kwargs)\n",
        "        self.p = p\n",
        "        self.c = c\n",
        "        self.oc = c\n",
        "        self.trainable_c = trainable_c\n",
        "        self.initializer = initializers.get(initializer)\n",
        "        self.regularizer = regularizers.get(regularizer)\n",
        "        self.constraint = constraints.get(constraint)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.trainable_c:\n",
        "            self.c = self.add_weight(\n",
        "                shape=(),\n",
        "                initializer=self.initializer,\n",
        "                regularizer=self.regularizer,\n",
        "                constraint=self.constraint,\n",
        "                name='{}_c'.format(self.name),\n",
        "            )\n",
        "        super(PolynomialKernel, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return (K.dot(inputs[0], inputs[1]) + self.c) ** self.p\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'p': self.p,\n",
        "            'c': self.oc,\n",
        "            'trainable_c': self.trainable_c,\n",
        "            'initializer': initializers.serialize(self.initializer),\n",
        "            'regularizer': regularizers.serialize(self.regularizer),\n",
        "            'constraint': initializers.serialize(self.constraint),\n",
        "        }\n",
        "        base_config = super(PolynomialKernel, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlXmqV3Eplf5"
      },
      "source": [
        "def squash(x, axis=-1):\n",
        "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
        "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
        "    return scale * x\n",
        "\n",
        "\n",
        "# define our own softmax function instead of K.softmax\n",
        "# because K.softmax can not specify axis.\n",
        "def softmax(x, axis=-1):\n",
        "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
        "    return ex / K.sum(ex, axis=axis, keepdims=True)\n",
        "\n",
        "\n",
        "# define the margin loss like hinge loss\n",
        "def margin_loss(y_true, y_pred):\n",
        "    lamb, margin = 0.5, 0.1\n",
        "    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
        "        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)\n",
        "\n",
        "\n",
        "class Capsule(Layer):\n",
        "    \"\"\"A Capsule Implement with Pure Keras\n",
        "    There are two vesions of Capsule.\n",
        "    One is like dense layer (for the fixed-shape input),\n",
        "    and the other is like timedistributed dense (for various length input).\n",
        "\n",
        "    The input shape of Capsule must be (batch_size,\n",
        "                                        input_num_capsule,\n",
        "                                        input_dim_capsule\n",
        "                                       )\n",
        "    and the output shape is (batch_size,\n",
        "                             num_capsule,\n",
        "                             dim_capsule\n",
        "                            )\n",
        "\n",
        "    Capsule Implement is from https://github.com/bojone/Capsule/\n",
        "    Capsule Paper: https://arxiv.org/abs/1710.09829\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_capsule,\n",
        "                 dim_capsule,\n",
        "                 routings=3,\n",
        "                 share_weights=True,\n",
        "                 activation='squash',\n",
        "                 **kwargs):\n",
        "        super(Capsule, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.share_weights = share_weights\n",
        "        if activation == 'squash':\n",
        "            self.activation = squash\n",
        "        else:\n",
        "            self.activation = activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim_capsule = input_shape[-1]\n",
        "        if self.share_weights:\n",
        "            self.kernel = self.add_weight(\n",
        "                name='capsule_kernel',\n",
        "                shape=(1, input_dim_capsule,\n",
        "                       self.num_capsule * self.dim_capsule),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "        else:\n",
        "            input_num_capsule = input_shape[-2]\n",
        "            self.kernel = self.add_weight(\n",
        "                name='capsule_kernel',\n",
        "                shape=(input_num_capsule, input_dim_capsule,\n",
        "                       self.num_capsule * self.dim_capsule),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Following the routing algorithm from Hinton's paper,\n",
        "        but replace b = b + <u,v> with b = <u,v>.\n",
        "\n",
        "        This change can improve the feature representation of Capsule.\n",
        "\n",
        "        However, you can replace\n",
        "            b = K.batch_dot(outputs, hat_inputs, [2, 3])\n",
        "        with\n",
        "            b += K.batch_dot(outputs, hat_inputs, [2, 3])\n",
        "        to realize a standard routing.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.share_weights:\n",
        "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
        "        else:\n",
        "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
        "\n",
        "        batch_size = K.shape(inputs)[0]\n",
        "        input_num_capsule = K.shape(inputs)[1]\n",
        "        hat_inputs = K.reshape(hat_inputs,\n",
        "                               (batch_size, input_num_capsule,\n",
        "                                self.num_capsule, self.dim_capsule))\n",
        "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
        "\n",
        "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
        "        for i in range(self.routings):\n",
        "            c = softmax(b, 1)\n",
        "            o = self.activation(K.batch_dot(c, hat_inputs, [2, 2]))\n",
        "            if i < self.routings - 1:\n",
        "                b = K.batch_dot(o, hat_inputs, [2, 3])\n",
        "                if K.backend() == 'theano':\n",
        "                    o = K.sum(o, axis=1)\n",
        "\n",
        "        return o\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (None, self.num_capsule, self.dim_capsule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wtsjjs3xWjv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "a808e09a-388f-4858-97b3-6d2cade2b8de"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsiQ6bY3xc-W"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers  as ppb \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLC4TNlixdDy"
      },
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "#We can use BERT but here I am using DistillBERT because BERT requires more RAM then available in the colab,but to use BERT just uncomment the next line and comment the previous line\n",
        "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)\n",
        "#To run the model on GPU\n",
        "#model.cuda()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOboMZN8xdXQ"
      },
      "source": [
        "#Importing the dataset\n",
        "import pandas as pd\n",
        " \n",
        "dataset=pd.read_csv('/content/1000_tweets_2_user_new_non-bot.csv')\n",
        "#dataset.iloc[:,0:1].fillna('other', inplace=True)\n",
        "y=dataset.iloc[:,1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ1EJJMsYkzk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "651bb2e2-8317-4f5d-ac44-59a43e61402d"
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeZV9Q0eVwWF"
      },
      "source": [
        "k=0\n",
        "X_train=[]\n",
        "y_train=[]\n",
        "for i in range(0,2):\n",
        "  for j in range(k,k+980):\n",
        "    X_train.append(dataset.iloc[j,0])\n",
        "    y_train.append(dataset.iloc[j,1])\n",
        "  k+=1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htmeebgkcM-s"
      },
      "source": [
        "k=980\n",
        "X_test=[]\n",
        "y_test=[]\n",
        "for i in range(0,2):\n",
        "  for j in range(k,k+20):\n",
        "    X_test.append(dataset.iloc[j,0])\n",
        "    y_test.append(dataset.iloc[j,1])\n",
        "  k+=1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTbPwVNscmaH"
      },
      "source": [
        "X_train=pd.DataFrame(X_train)\n",
        "X_test=pd.DataFrame(X_test)\n",
        "y_train=pd.DataFrame(y_train)\n",
        "y_test=pd.DataFrame(y_test)\n",
        "X_train=X_train.iloc[:,:].values\n",
        "X_test=X_test.iloc[:,:].values\n",
        "y_train=y_train.iloc[:,:].values\n",
        "y_test=y_test.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3jvP6gqd86H"
      },
      "source": [
        "train=np.concatenate((X_train,y_train),axis=1)\n",
        "test=np.concatenate((X_test,y_test),axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xRO2LX-eRnO"
      },
      "source": [
        "np.random.shuffle(train)\n",
        "np.random.shuffle(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtlYsn2fgkcZ"
      },
      "source": [
        "train=pd.DataFrame(train)\n",
        "test=pd.DataFrame(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1iU2aAigWeD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75b9534a-4b47-4f23-de4e-b4fdbf6fc607"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 353
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Vw48THZIQP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "3aa0bcdb-e49a-4c16-9b2e-e1c08575d9c4"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [71166537],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064],\n",
              "       [18123064]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 354
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnQqY1bLPqL9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "00f63cc3-cec2-4c5d-a22a-bbca7fe7ee39"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB5jEwy3g5A2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6fe5c340-0cab-4617-a3bd-18c0fdd2031f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocejWEWFfcav"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer() \n",
        "\n",
        "def preprocess(sentence):\n",
        "  sentence=str(sentence)\n",
        "  sentence = sentence.lower()\n",
        "  sentence=sentence.replace('{html}',\"\") \n",
        "  cleanr = re.compile('<.*?>#@')\n",
        "  cleantext = re.sub(cleanr, '', sentence)\n",
        "  rem_url=re.sub(r'http\\S+', '',cleantext)\n",
        "  rem_num = re.sub('[0-9]+', '', rem_url)\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(rem_num)  \n",
        "  filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "  stem_words=[stemmer.stem(w) for w in filtered_words]\n",
        "  lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
        "  return \" \".join(filtered_words)\n",
        "\n",
        "\n",
        "train.iloc[:,0]=train.iloc[:,0].map(lambda s:preprocess(s))\n",
        "test.iloc[:,0]=test.iloc[:,0].map(lambda s:preprocess(s))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "147cw9MMXtsW"
      },
      "source": [
        "X_train=train.iloc[:,0]\n",
        "X_test=test.iloc[:,0]\n",
        "y_train=train.iloc[:,1]\n",
        "y_test=test.iloc[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxS9GpdhZbgA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "44a1588f-72fa-4970-e940-14931c1e6e5c"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 51964081,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731,\n",
              " 90078731]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p4KyUOSxdes"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_train)\n",
        "encoded_Y = encoder.transform(y_train)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "y_train = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2hURH3KjkZr"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_test)\n",
        "encoded_Y = encoder.transform(y_test)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "y_test = np_utils.to_categorical(encoded_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smtGSDiPjfmL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "3468884f-f4b6-42b4-9ae1-86b8c986c9ed"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 358
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMbVVZDmY9No",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "5643959e-bd86-40da-d2f8-cda43bd375db"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 359
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jjgjMNckJ-I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "92e6d83d-c819-4d7d-f8d9-375293fe3314"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1960, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 360
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DupigB-oxdbC"
      },
      "source": [
        "X_train=pd.DataFrame(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SX4G2EoxdUx"
      },
      "source": [
        "tokenized = X_train.iloc[:,0].apply((lambda x: tokenizer.encode(str(x), add_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayjDsHxXxdST"
      },
      "source": [
        "\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iVhzK8zxdP-"
      },
      "source": [
        "#for adding paddings\n",
        "input_ids = torch.tensor(np.array(padded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SLYToopxdON",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd800355-365d-467d-ba87-268f00949663"
      },
      "source": [
        "#to set the paddings to zero and rest to 1\n",
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1960, 77)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 365
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H2En2sbxdL4"
      },
      "source": [
        "input_ids = (torch.tensor(padded))\n",
        "attention_mask = (torch.tensor(attention_mask))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tQqZ6fJxdI2"
      },
      "source": [
        "with torch.no_grad():\n",
        "    last_hidden_states_train = model(input_ids,attention_mask)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofcSDLXLRHIJ"
      },
      "source": [
        "X_train=last_hidden_states_train[0].numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l65g5-3PWDC-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aac5e1be-bd2a-4d1a-bc98-2231b6394069"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1960, 77, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 369
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7kpv6iGxdGw"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_eval, y_train, y_eval = train_test_split(last_hidden_states_train[0].numpy(),y_train, test_size = 0.05, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYD77iCGL-cg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2d22480b-37a8-4319-f89f-bb6e14ca5f29"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-9.36981291e-02,  2.27245018e-02,  7.05619305e-02, ...,\n",
              "         -1.36370838e-01,  2.12881833e-01,  3.43180418e-01],\n",
              "        [ 1.07830115e-01,  2.04664588e-01, -1.65369362e-01, ...,\n",
              "         -6.50881827e-02,  4.73617852e-01,  1.52222201e-01],\n",
              "        [-1.66791171e-01,  1.30414575e-01,  2.72202075e-01, ...,\n",
              "          1.95829552e-02, -2.45518342e-01, -5.60819805e-01],\n",
              "        ...,\n",
              "        [ 6.28547743e-02,  4.42062430e-02,  1.98746622e-01, ...,\n",
              "          2.17413763e-03, -1.16380632e-01,  1.62709370e-01],\n",
              "        [ 9.43285897e-02, -5.66063933e-02,  1.50588332e-02, ...,\n",
              "         -2.19485201e-02, -1.53976813e-01,  2.01601833e-01],\n",
              "        [-6.33209944e-03, -1.23350672e-01,  1.96025103e-01, ...,\n",
              "         -9.41810906e-02, -2.17934832e-01,  1.28147349e-01]],\n",
              "\n",
              "       [[ 9.05493349e-02, -1.89240023e-01,  1.81339130e-01, ...,\n",
              "         -1.00806184e-01,  2.46982887e-01,  4.44152653e-01],\n",
              "        [ 3.38109821e-01,  1.10043384e-01,  4.33619171e-01, ...,\n",
              "         -2.00119346e-01,  4.42347199e-01,  3.20326500e-02],\n",
              "        [ 2.68386066e-01,  1.41676813e-01,  8.80627811e-01, ...,\n",
              "          2.79074103e-01,  1.44000620e-01, -7.61814713e-01],\n",
              "        ...,\n",
              "        [-1.57757029e-01,  2.74075121e-01,  2.21388906e-01, ...,\n",
              "         -1.69783421e-02,  2.22421408e-01,  1.43635005e-01],\n",
              "        [ 2.74406970e-01,  6.07012585e-03,  1.83657199e-01, ...,\n",
              "         -1.63155243e-01, -1.57580584e-01,  2.88639814e-01],\n",
              "        [ 4.71640140e-01, -4.39576991e-02,  3.86023909e-01, ...,\n",
              "         -1.93349704e-01, -2.34768763e-02,  3.60927254e-01]],\n",
              "\n",
              "       [[-1.98566824e-01, -1.40466318e-01,  2.15512350e-01, ...,\n",
              "          4.88202982e-02,  2.34279037e-01,  3.14390153e-01],\n",
              "        [ 4.04640079e-01,  7.23174810e-02,  4.26133335e-01, ...,\n",
              "         -8.49516541e-02,  3.44261378e-01,  5.11114597e-02],\n",
              "        [ 1.58745170e-01,  1.72695726e-01,  7.76618302e-01, ...,\n",
              "          3.25166732e-01,  1.80063285e-02, -6.09214842e-01],\n",
              "        ...,\n",
              "        [ 3.00145626e-01, -1.17439598e-01,  4.14617062e-01, ...,\n",
              "         -7.27538671e-03, -2.41615772e-01,  4.50739831e-01],\n",
              "        [ 3.73947442e-01, -1.39664620e-01,  1.94186464e-01, ...,\n",
              "         -4.08324562e-02, -3.81474346e-01,  6.08634770e-01],\n",
              "        [ 3.14414412e-01, -1.91666335e-01,  3.44428360e-01, ...,\n",
              "          1.17650010e-01, -3.50154370e-01,  5.19786656e-01]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 9.94241089e-02, -1.49901047e-01, -3.31016956e-03, ...,\n",
              "          3.43186185e-02,  9.09974575e-02,  6.09838486e-01],\n",
              "        [ 5.24004400e-01,  1.88154355e-02,  2.66552120e-01, ...,\n",
              "         -6.47621900e-02,  3.86791378e-01,  2.75923479e-02],\n",
              "        [ 2.57179856e-01, -1.97999123e-02,  5.18231392e-01, ...,\n",
              "          4.14525270e-01,  1.19050354e-01, -3.39504629e-01],\n",
              "        ...,\n",
              "        [ 8.70255232e-02,  9.13485046e-03,  2.76223481e-01, ...,\n",
              "          3.95196170e-04, -2.91079938e-01,  4.33199733e-01],\n",
              "        [ 1.59529343e-01,  3.36462021e-01,  4.56821740e-01, ...,\n",
              "          1.98072083e-02, -9.92154106e-02,  4.10625428e-01],\n",
              "        [ 1.77851483e-01,  3.09517998e-02,  3.20899606e-01, ...,\n",
              "         -3.16560678e-02, -2.76964635e-01,  4.89680946e-01]],\n",
              "\n",
              "       [[-4.55635898e-02, -2.57615387e-01,  5.69849461e-03, ...,\n",
              "         -1.34158120e-01,  4.63866085e-01,  4.10343468e-01],\n",
              "        [ 4.57932413e-01,  2.99576610e-01,  3.05991620e-01, ...,\n",
              "          3.33568826e-03,  6.40477359e-01,  6.37094304e-02],\n",
              "        [-1.72163859e-01,  1.45904481e-01,  3.19985479e-01, ...,\n",
              "          1.81419000e-01,  2.13430896e-01, -1.70166776e-01],\n",
              "        ...,\n",
              "        [ 5.97530715e-02,  3.50409225e-02,  2.98792809e-01, ...,\n",
              "         -3.64495739e-02, -2.31175020e-01,  3.84640664e-01],\n",
              "        [-3.34916599e-02, -6.12671748e-02,  4.82208818e-01, ...,\n",
              "         -3.86862759e-03, -3.01734626e-01,  4.43834573e-01],\n",
              "        [ 5.59919775e-02, -9.97040346e-02,  3.31959546e-01, ...,\n",
              "         -1.23376558e-02, -1.58283070e-01,  3.33917975e-01]],\n",
              "\n",
              "       [[-1.53561775e-02, -3.79434787e-02,  2.52622336e-01, ...,\n",
              "         -2.42347270e-01,  2.12267563e-01,  5.82827389e-01],\n",
              "        [ 1.67028248e-01,  1.53450325e-01,  3.29596221e-01, ...,\n",
              "         -2.79560626e-01,  4.87887442e-01,  1.33399889e-01],\n",
              "        [-1.54834036e-02,  1.45591483e-01,  8.39617968e-01, ...,\n",
              "          1.39167130e-01,  4.71131578e-02, -4.32044923e-01],\n",
              "        ...,\n",
              "        [ 1.41852563e-02,  1.81295410e-01,  2.69350052e-01, ...,\n",
              "         -2.05348656e-01,  1.33818716e-01,  1.61810294e-01],\n",
              "        [ 2.03124076e-01,  3.72321196e-02,  2.64555961e-01, ...,\n",
              "         -2.04228237e-01, -2.51492839e-02,  9.57721546e-02],\n",
              "        [ 4.32619184e-01, -2.30240300e-01,  4.77434129e-01, ...,\n",
              "          1.93968371e-01,  4.46906276e-02,  3.34831417e-01]]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 371
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaRz3wbDju6u"
      },
      "source": [
        "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import Input, Dense, Dropout, Flatten\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syNIGGChY6s9"
      },
      "source": [
        "gru_len = 128\n",
        "Routings = 5\n",
        "Num_capsule = 10\n",
        "Dim_capsule = 16\n",
        "dropout_p = 0.3\n",
        "rate_drop_dense = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YibY6lf7sNPf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "7aa72bf6-44a5-4e1d-dca4-e2dafbd6fa75"
      },
      "source": [
        "\n",
        "classifier = Sequential()\n",
        "classifier.add(KernelConv2D(\n",
        "    input_shape=(77,768),\n",
        "    filters=128,\n",
        "    kernel_size=1,\n",
        "    kernel_function=PolynomialKernel(p=2, trainable_c=True),\n",
        "))\n",
        "classifier.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "#classifier.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
        "classifier.add(AveragePooling1D(3))\n",
        "classifier.add(Capsule(num_capsule=1 ,dim_capsule=64, routings=1,share_weights=True))\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(units=2 , activation='softmax'))\n",
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "kernel_conv2d_20 (KernelConv (None, 77, 128)           98433     \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 75, 32)            12320     \n",
            "_________________________________________________________________\n",
            "average_pooling1d_18 (Averag (None, 25, 32)            0         \n",
            "_________________________________________________________________\n",
            "capsule_18 (Capsule)         (None, 1, 1, 64)          2048      \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 112,931\n",
            "Trainable params: 112,931\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-rs_DvXxaXo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "af7409ff-4540-4958-b442-c188db4213d8"
      },
      "source": [
        "classifier.fit(np.array(X_train),np.array(y_train),batch_size=128,epochs=3,validation_data=(np.array(X_eval),np.array(y_eval)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.4226 - accuracy: 0.9082 - val_loss: 0.2140 - val_accuracy: 0.9898\n",
            "Epoch 2/3\n",
            "15/15 [==============================] - 2s 119ms/step - loss: 0.1625 - accuracy: 0.9941 - val_loss: 0.1289 - val_accuracy: 0.9898\n",
            "Epoch 3/3\n",
            "15/15 [==============================] - 2s 118ms/step - loss: 0.1058 - accuracy: 0.9968 - val_loss: 0.0898 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc5e97c6b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 386
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eix1jvJptX1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "02e7b8f5-c222-4818-af4f-52bec96a364c"
      },
      "source": [
        "file=open(\"heatmap_kervolution_bot.html\",\"w\")\n",
        "for i in range(0,20):\n",
        "  type_here=[]\n",
        "  type_here.append(X_train1[i])\n",
        "  typr_here=pd.DataFrame(type_here)\n",
        "  tokenized = typr_here.iloc[:,0].apply((lambda x: tokenizer.encode(str(x), add_special_tokens=True)))\n",
        "  padded = np.array([i + [0]*(77-len(i)) for i in tokenized.values])\n",
        "  input_ids = torch.tensor(np.array(padded))\n",
        "  attention_mask = np.where(padded != 0, 1, 0)\n",
        "  input_ids = (torch.tensor(padded))\n",
        "  attention_mask = (torch.tensor(attention_mask))\n",
        "  with torch.no_grad():\n",
        "    last_hidden_states_test = model(input_ids,attention_mask)\n",
        "  y_pred = classifier.predict(last_hidden_states_test[0].numpy())\n",
        "  Xtst=last_hidden_states_test[0]\n",
        "  class_idx = np.argmax(y_pred[0]) #not needed in this case as only two classes\n",
        "  class_output = classifier.output[:, class_idx]\n",
        "  last_conv_layer = classifier.get_layer(\"kernel_conv2d_20\")\n",
        "  grads = K1.gradients(class_output, last_conv_layer.output)[0]\n",
        "  pooled_grads = K1.mean(grads)\n",
        "  iterate = K1.function([classifier.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "  pooled_grads_value, conv_layer_output_value = iterate([Xtst])\n",
        "  heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
        "  heatmap = np.maximum(heatmap,0)\n",
        "  heatmap /= np.max(heatmap)#normalise values in the prediction\n",
        "  norm_len = 36/last_conv_layer.output_shape[1]\n",
        "  html = \"\"\n",
        "  if y_pred[0][0]>0.5:\n",
        "    pred = '90078731'\n",
        "  else:\n",
        "    pred = '51964081'\n",
        "  html += \"<span><h3>Based on the description, the model believes that text belongs to {} author \".format(pred)\n",
        "  html += \"<small><br>Confidence: {:.0f}%<br><br></small></h3></span>\".format(abs(((y_pred[0][0]*100)-50)*2))\n",
        "  for j,i in enumerate(type_here[0].split()):\n",
        "    html += \"<span style='background-color:rgba({},0,15,{})'>{} </span>\".format(heatmap[math.floor(j/norm_len)]*255,heatmap[math.floor(j/norm_len)]-0.3,i)\n",
        "  file.write(html)\n",
        "file.close()\n",
        "HTML(html)   \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<span><h3>Based on the description, the model believes that text belongs to 51964081 author <small><br>Confidence: 84%<br><br></small></h3></span><span style='background-color:rgba(62.964715138077736,0,15,-0.053079548478126515)'>b'Chair </span><span style='background-color:rgba(81.13364920020103,0,15,0.018171173334121715)'>and </span><span style='background-color:rgba(70.54062321782112,0,15,-0.023370105028152455)'>footrest </span><span style='background-color:rgba(63.88138175010681,0,15,-0.04948477745056151)'>(Conroe): </span><span style='background-color:rgba(54.27267774939537,0,15,-0.08716596961021422)'>Chair </span><span style='background-color:rgba(60.444158390164375,0,15,-0.06296408474445342)'>and </span><span style='background-color:rgba(66.4391840994358,0,15,-0.03945418000221251)'>footrest </span><span style='background-color:rgba(61.852134838700294,0,15,-0.05744260847568511)'>needs </span><span style='background-color:rgba(61.5647828578949,0,15,-0.05856947898864745)'>to </span><span style='background-color:rgba(76.41871020197868,0,15,-0.0003187835216522106)'>be </span><span style='background-color:rgba(168.0301147699356,0,15,0.3589416265487671)'>recovered, </span><span style='background-color:rgba(94.33418646454811,0,15,0.0699379861354828)'>but </span><span style='background-color:rgba(61.12382411956787,0,15,-0.06029872894287108)'>it </span><span style='background-color:rgba(76.04648217558861,0,15,-0.001778501272201527)'>is </span><span style='background-color:rgba(63.056408017873764,0,15,-0.05271996855735778)'>solid </span><span style='background-color:rgba(196.55988067388535,0,15,0.47082306146621705)'>wood </span><span style='background-color:rgba(187.38021165132523,0,15,0.4348243594169617)'>and </span><span style='background-color:rgba(193.67955923080444,0,15,0.45952768325805665)'>very </span><span style='background-color:rgba(87.56966024637222,0,15,0.04341043233871461)'>comfortable. </span><span style='background-color:rgba(68.08213233947754,0,15,-0.03301124572753905)'>http://bit.ly/17F32e\\n' </span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 388
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vacRAzw9_6e_"
      },
      "source": [
        "\n",
        "X_test=pd.DataFrame(X_test)\n",
        "tokenized = X_test.iloc[:,0].apply((lambda x: tokenizer.encode(str(x), add_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PcF9TNcnzQJ"
      },
      "source": [
        "\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(51-len(i)) for i in tokenized.values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw8VLv9xn2qT"
      },
      "source": [
        "#for adding paddings\n",
        "input_ids = torch.tensor(np.array(padded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVV6DOTBn5sp"
      },
      "source": [
        "#for adding paddings\n",
        "input_ids = torch.tensor(np.array(padded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znn22pELn7wV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0051ab86-1922-4f90-d85b-69f4cd1b4ad6"
      },
      "source": [
        "#to set the paddings to zero and rest to 1\n",
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250, 51)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnuKTX0bn-HS"
      },
      "source": [
        "input_ids = (torch.tensor(padded))\n",
        "attention_mask = (torch.tensor(attention_mask))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LUWUnU5oAWM"
      },
      "source": [
        "with torch.no_grad():\n",
        "    last_hidden_states_test = model(input_ids,attention_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnNmbXlEG7Rs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ea32aae-5c14-4a0b-94b2-d7c3a8b0de55"
      },
      "source": [
        "last_hidden_states_test[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([250, 51, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9no8390o3Yo"
      },
      "source": [
        "X_test=last_hidden_states_test[0].numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbx4PWycoCfn"
      },
      "source": [
        "y_pred =  classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fglS7d6OofNB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "9e0a1966-eaa4-4430-b4b2-98fcc79add40"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01956765, 0.00745   , 0.03455538, ..., 0.00793293, 0.00837867,\n",
              "        0.0050374 ],\n",
              "       [0.00535491, 0.05970927, 0.01223011, ..., 0.02090672, 0.00927505,\n",
              "        0.00465346],\n",
              "       [0.00195544, 0.0022589 , 0.00247086, ..., 0.00280461, 0.00441738,\n",
              "        0.00767668],\n",
              "       ...,\n",
              "       [0.26415133, 0.03437058, 0.01567418, ..., 0.00672165, 0.0059067 ,\n",
              "        0.01181264],\n",
              "       [0.01686945, 0.01717686, 0.02739022, ..., 0.01563231, 0.00881726,\n",
              "        0.0091142 ],\n",
              "       [0.01239913, 0.00452661, 0.01392127, ..., 0.00327289, 0.00521482,\n",
              "        0.00444992]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZPydKvEpKW8"
      },
      "source": [
        "\n",
        "#TO get maximum value as 1 and rest to zero\n",
        "y_pred=pd.DataFrame(y_pred)\n",
        "y_pred=y_pred.eq(y_pred.where(y_pred != 0).max(1), axis=0).astype(int)\n",
        "y_pred=y_pred.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd0SBWMfpURT"
      },
      "source": [
        "y_test=pd.DataFrame(y_test)\n",
        "y_test=y_test.eq(y_test.where(y_test != 0).max(1), axis=0).astype(int)\n",
        "y_test=y_test.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buz-mVFFpWlZ"
      },
      "source": [
        "\n",
        "result=[]\n",
        "for i in range(0,len(y_test)):\n",
        "  for j in range(0,len(y_test[0])):\n",
        "    if(y_test[i][j]==1):\n",
        "      result.append(j)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcYtuRtwpYga"
      },
      "source": [
        "predicted=[]\n",
        "for i in range(0,len(y_pred)):\n",
        "  for j in range(0,len(y_pred[0])):\n",
        "    if(y_pred[i][j]==1):\n",
        "      predicted.append(j)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xawu30c3YnTG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY9LOftTpb0O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "cdae26bb-a489-4843-8504-6a835d298aeb"
      },
      "source": [
        "\n",
        "\n",
        "print(result)\n",
        "print(predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9, 30, 39, 18, 40, 8, 28, 4, 9, 43, 49, 13, 42, 6, 35, 48, 16, 44, 35, 21, 24, 23, 3, 20, 19, 12, 2, 22, 9, 37, 20, 17, 43, 48, 26, 14, 9, 3, 2, 9, 16, 49, 47, 13, 11, 48, 19, 45, 47, 17, 35, 27, 31, 14, 11, 19, 43, 22, 33, 13, 17, 37, 36, 29, 10, 10, 44, 18, 12, 4, 31, 41, 18, 41, 46, 38, 29, 37, 39, 40, 40, 0, 0, 7, 37, 44, 46, 17, 41, 34, 11, 32, 33, 38, 24, 4, 20, 34, 22, 38, 34, 33, 5, 41, 15, 3, 2, 15, 16, 11, 35, 48, 37, 22, 12, 25, 49, 43, 30, 7, 36, 8, 45, 6, 40, 42, 38, 3, 15, 29, 29, 5, 8, 47, 32, 3, 2, 18, 26, 31, 30, 13, 10, 31, 33, 26, 26, 17, 5, 16, 21, 27, 45, 31, 1, 23, 38, 13, 25, 0, 49, 36, 34, 20, 41, 21, 1, 32, 7, 19, 10, 16, 19, 8, 15, 4, 47, 4, 39, 1, 7, 42, 25, 24, 46, 36, 30, 28, 39, 23, 44, 25, 23, 21, 0, 1, 1, 28, 25, 21, 33, 14, 10, 36, 47, 8, 42, 30, 28, 35, 2, 11, 27, 32, 32, 24, 27, 44, 12, 7, 6, 43, 6, 12, 6, 45, 14, 42, 34, 29, 22, 48, 23, 26, 45, 46, 28, 18, 39, 5, 46, 20, 5, 40, 49, 15, 27, 0, 14, 24]\n",
            "[8, 15, 39, 42, 40, 4, 28, 4, 38, 43, 49, 0, 40, 5, 18, 48, 19, 20, 35, 1, 19, 29, 43, 20, 19, 19, 2, 33, 29, 37, 0, 6, 48, 48, 47, 8, 26, 3, 2, 35, 49, 49, 44, 19, 11, 48, 43, 45, 47, 25, 38, 7, 0, 2, 3, 19, 43, 0, 13, 2, 24, 37, 7, 29, 7, 5, 42, 36, 18, 4, 23, 22, 45, 1, 43, 29, 47, 37, 39, 33, 40, 3, 3, 7, 37, 35, 43, 29, 22, 34, 11, 7, 35, 38, 24, 43, 20, 34, 2, 19, 34, 2, 29, 8, 28, 4, 25, 24, 16, 11, 22, 48, 37, 44, 30, 18, 49, 46, 1, 7, 20, 25, 45, 6, 40, 25, 26, 21, 44, 2, 29, 48, 0, 22, 11, 8, 11, 35, 43, 19, 1, 13, 2, 38, 26, 1, 8, 5, 22, 16, 2, 27, 45, 31, 29, 43, 35, 13, 6, 0, 49, 36, 34, 19, 25, 44, 2, 0, 7, 16, 18, 16, 19, 36, 47, 27, 15, 3, 39, 13, 7, 11, 20, 24, 1, 8, 28, 29, 39, 15, 21, 38, 2, 1, 1, 19, 36, 47, 1, 22, 33, 0, 15, 5, 13, 19, 15, 33, 22, 11, 1, 11, 27, 8, 19, 24, 27, 44, 22, 7, 26, 22, 11, 22, 43, 45, 20, 26, 34, 29, 22, 48, 11, 26, 48, 43, 12, 36, 39, 18, 43, 19, 26, 40, 49, 42, 48, 0, 18, 24]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phqCIAW0Y0_p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "998b706f-a0ba-4295-b1ea-e7c2cd56075d"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32sY2QHWpdxK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "9c76704e-a606-497e-e9b5-f9ebfcfe62e6"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(result,predicted)\n",
        "\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 1, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 1, ..., 0, 0, 0],\n",
              "       [0, 1, 2, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 5, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvfWehqOpg8X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "342ad06f-6f18-4525-d0d8-68657f54a878"
      },
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "print('Confusion Matrix :')\n",
        "print(cm) \n",
        "print('Accuracy Score :',accuracy_score(result, predicted)) \n",
        "print('Report : ')\n",
        "print(classification_report(result, predicted)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[2 1 0 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 1 2 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 0 5 0]\n",
            " [0 0 0 ... 0 0 5]]\n",
            "Accuracy Score : 0.328\n",
            "Report : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.40      0.29         5\n",
            "           1       0.00      0.00      0.00         5\n",
            "           2       0.18      0.40      0.25         5\n",
            "           3       0.20      0.20      0.20         5\n",
            "           4       0.50      0.40      0.44         5\n",
            "           5       0.00      0.00      0.00         5\n",
            "           6       0.33      0.20      0.25         5\n",
            "           7       0.56      1.00      0.71         5\n",
            "           8       0.00      0.00      0.00         5\n",
            "           9       0.00      0.00      0.00         5\n",
            "          10       0.00      0.00      0.00         5\n",
            "          11       0.40      0.80      0.53         5\n",
            "          12       0.00      0.00      0.00         5\n",
            "          13       0.40      0.40      0.40         5\n",
            "          14       0.00      0.00      0.00         5\n",
            "          15       0.00      0.00      0.00         5\n",
            "          16       0.75      0.60      0.67         5\n",
            "          17       0.00      0.00      0.00         5\n",
            "          18       0.00      0.00      0.00         5\n",
            "          19       0.21      0.60      0.32         5\n",
            "          20       0.33      0.40      0.36         5\n",
            "          21       0.00      0.00      0.00         5\n",
            "          22       0.09      0.20      0.13         5\n",
            "          23       0.00      0.00      0.00         5\n",
            "          24       0.67      0.80      0.73         5\n",
            "          25       0.00      0.00      0.00         5\n",
            "          26       0.14      0.20      0.17         5\n",
            "          27       0.75      0.60      0.67         5\n",
            "          28       0.33      0.20      0.25         5\n",
            "          29       0.30      0.60      0.40         5\n",
            "          30       0.00      0.00      0.00         5\n",
            "          31       1.00      0.20      0.33         5\n",
            "          32       0.00      0.00      0.00         5\n",
            "          33       0.25      0.20      0.22         5\n",
            "          34       1.00      1.00      1.00         5\n",
            "          35       0.17      0.20      0.18         5\n",
            "          36       0.20      0.20      0.20         5\n",
            "          37       1.00      1.00      1.00         5\n",
            "          38       0.20      0.20      0.20         5\n",
            "          39       1.00      1.00      1.00         5\n",
            "          40       0.80      0.80      0.80         5\n",
            "          41       0.00      0.00      0.00         5\n",
            "          42       0.00      0.00      0.00         5\n",
            "          43       0.17      0.40      0.24         5\n",
            "          44       0.20      0.20      0.20         5\n",
            "          45       0.80      0.80      0.80         5\n",
            "          46       0.00      0.00      0.00         5\n",
            "          47       0.20      0.20      0.20         5\n",
            "          48       0.56      1.00      0.71         5\n",
            "          49       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.33       250\n",
            "   macro avg       0.29      0.33      0.30       250\n",
            "weighted avg       0.29      0.33      0.30       250\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeS6Jyfd-Lf_"
      },
      "source": [
        "k=980\n",
        "X_train1=[]\n",
        "y_train1=[]\n",
        "for i in range(0,2):\n",
        "  for j in range(k,k+20):\n",
        "    X_train1.append(dataset.iloc[j,0])\n",
        "    y_train1.append(dataset.iloc[j,1])\n",
        "  k+=1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2dkuH2E-IME",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "1f4bcd1c-942e-448b-9290-6e23948c174f"
      },
      "source": [
        "file=open(\"heatmap_kervolution_bot.html\",\"w\")\n",
        "for i in range(0,1):\n",
        "  type_here=[]\n",
        "  type_here.append(X_train1[i])\n",
        "  typr_here=pd.DataFrame(type_here)\n",
        "  tokenized = typr_here.iloc[:,0].apply((lambda x: tokenizer.encode(str(x), add_special_tokens=True)))\n",
        "  padded = np.array([i + [0]*(82-len(i)) for i in tokenized.values])\n",
        "  input_ids = torch.tensor(np.array(padded))\n",
        "  attention_mask = np.where(padded != 0, 1, 0)\n",
        "  input_ids = (torch.tensor(padded))\n",
        "  attention_mask = (torch.tensor(attention_mask))\n",
        "  with torch.no_grad():\n",
        "    last_hidden_states_test = model(input_ids,attention_mask)\n",
        "  y_pred = classifier.predict(last_hidden_states_test[0].numpy())\n",
        "  Xtst=last_hidden_states_test[0]\n",
        "  class_idx = np.argmax(y_pred[0]) #not needed in this case as only two classes\n",
        "  class_output = classifier.output[:, class_idx]\n",
        "  last_conv_layer = classifier.get_layer(\"kernel_conv2d_8\")\n",
        "  grads = K1.gradients(class_output, last_conv_layer.output)[0]\n",
        "  pooled_grads = K1.mean(grads)\n",
        "  iterate = K1.function([classifier.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "  pooled_grads_value, conv_layer_output_value = iterate([Xtst])\n",
        "  heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
        "  heatmap = np.maximum(heatmap,0)\n",
        "  heatmap /= np.max(heatmap)#normalise values in the prediction\n",
        "  norm_len = 36/last_conv_layer.output_shape[1]\n",
        "  html = \"\"\n",
        "  if y_pred[0][0]>0.5:\n",
        "    pred = '90078731'\n",
        "  else:\n",
        "    pred = '51964081'\n",
        "  html += \"<span><h3>Based on the description, the model believes that text belongs to {} author \".format(pred)\n",
        "  html += \"<small><br>Confidence: {:.0f}%<br><br></small></h3></span>\".format(abs(((y_pred[0][0]*100)-50)*2))\n",
        "  for j,i in enumerate(type_here[0].split()):\n",
        "    html += \"<span style='background-color:rgba({},0,15,{})'>{} </span>\".format(heatmap[math.floor(j/norm_len)]*255,heatmap[math.floor(j/norm_len)]-0.3,i)\n",
        "  #file.write(html)\n",
        "#file.close()\n",
        "HTML(html)   \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<span><h3>Based on the description, the model believes that text belongs to 90078731 author <small><br>Confidence: 92%<br><br></small></h3></span><span style='background-color:rgba(11.369845848530531,0,15,-0.2554123692214489)'>b'The </span><span style='background-color:rgba(4.971465608105063,0,15,-0.28050405643880366)'>time </span><span style='background-color:rgba(68.83039578795433,0,15,-0.030076879262924183)'>in </span><span style='background-color:rgba(3.60652232542634,0,15,-0.2858567751944065)'>Hollywood, </span><span style='background-color:rgba(132.46514797210693,0,15,0.21947116851806642)'>CA, </span><span style='background-color:rgba(16.248528510332108,0,15,-0.23628028035163878)'>is </span><span style='background-color:rgba(48.651715368032455,0,15,-0.10920895934104918)'>10:19:33 </span><span style='background-color:rgba(78.66039231419563,0,15,0.008472126722335827)'>pm\\n' </span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUd2sucRjY1X"
      },
      "source": [
        "type_here=[]\n",
        "type_here.append('Now playing: Hermes House Band - Country roads. Tune in: http://stream.laut.fm/eurodance.m3u\\n')\n",
        "typr_here=pd.DataFrame(type_here)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMvARWkX-rc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "126c130a-d6fe-4c8b-b07a-2a60e032af54"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from IPython.display import HTML\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras import backend as K1\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "\n",
        "pd.options.display.max_rows\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djNRCk2AjYwG"
      },
      "source": [
        "tokenized = typr_here.iloc[:,0].apply((lambda x: tokenizer.encode(str(x), add_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpfPNhMnjYs1"
      },
      "source": [
        "\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(82-len(i)) for i in tokenized.values])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRpnZ61wjYpN"
      },
      "source": [
        "\n",
        "input_ids = torch.tensor(np.array(padded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUbSOHEhjYl4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bca6aef3-632e-4a3b-d8b1-bb86e88824d0"
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 82)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igP82aEkjYjn"
      },
      "source": [
        "input_ids = (torch.tensor(padded))\n",
        "attention_mask = (torch.tensor(attention_mask))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU_tDLYCjYhM"
      },
      "source": [
        "with torch.no_grad():\n",
        "    last_hidden_states_test = model(input_ids,attention_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVYZtxsNjYeP"
      },
      "source": [
        "y_pred = classifier.predict(last_hidden_states_test[0].numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df40A3sSqhb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "873e2026-b4d1-46da-d682-4b6a433b6484"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03259752, 0.96740246]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDkw86mXjYbr"
      },
      "source": [
        "Xtst=last_hidden_states_test[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTXm27sJjYZB"
      },
      "source": [
        "class_idx = np.argmax(y_pred[0]) #not needed in this case as only two classes\n",
        "class_output = classifier.output[:, class_idx]\n",
        "last_conv_layer = classifier.get_layer(\"kernel_conv2d_5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJZ740mNsUrh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rZSEwLQjYTJ"
      },
      "source": [
        "grads = K1.gradients(class_output, last_conv_layer.output)[0]\n",
        "pooled_grads = K1.mean(grads)\n",
        "iterate = K1.function([classifier.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "pooled_grads_value, conv_layer_output_value = iterate([Xtst])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-_Tl8hxbLc2"
      },
      "source": [
        "\n",
        "heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
        "heatmap = np.maximum(heatmap,0)\n",
        "heatmap /= np.max(heatmap)#normalise values in the prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugJFoZYPpOB_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "bcb1ae1e-77e8-4bfc-b5c6-86a8c3f3bd2d"
      },
      "source": [
        "heatmap"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.04559674, 0.        , 0.        , 0.        , 0.08412105,\n",
              "       0.        , 0.00601779, 0.        , 0.07689551, 0.07597765,\n",
              "       0.        , 0.05312858, 0.6212722 , 0.7219944 , 0.        ,\n",
              "       0.25001332, 0.0473242 , 0.4543909 , 0.        , 0.        ,\n",
              "       0.7650527 , 0.        , 0.06201762, 0.        , 0.        ,\n",
              "       0.40358615, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.00117577, 0.03919426, 0.1703591 , 0.04175245,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.02942058, 0.11977235, 0.15400404,\n",
              "       0.03380042, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R4SoN8hpPU_"
      },
      "source": [
        "norm_len = 36/last_conv_layer.output_shape[1] # fi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_ZzqaxwpSeu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "18f160ee-5005-4cb3-c1f3-fa7cf05d0ab7"
      },
      "source": [
        "html = \"\"\n",
        "if y_pred[0][0]>0.5:\n",
        "  pred = '90078731'\n",
        "else:\n",
        "  pred = '15401533'\n",
        "html += \"<span><h3>Based on the description, the model believes that text belongs to {} author \".format(pred)\n",
        "html += \"<small><br>Confidence: {:.0f}%<br><br></small></h3></span>\".format(abs(((y_pred[0][0]*100)-50)*2))\n",
        "for j,i in enumerate(type_here[0].split()):\n",
        "  html += \"<span style='background-color:rgba({},0,150,{})'>{} </span>\".format(heatmap[math.floor(j/norm_len)]*255,heatmap[math.floor(j/norm_len)]-0.3,i)\n",
        "\n",
        "HTML(html)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<span><h3>Based on the description, the model believes that text belongs to 15401533 author <small><br>Confidence: 93%<br><br></small></h3></span><span style='background-color:rgba(0.0,0,150,-0.3)'>b'Now </span><span style='background-color:rgba(0.0,0,150,-0.3)'>playing: </span><span style='background-color:rgba(0.0,0,150,-0.3)'>Phantasia </span><span style='background-color:rgba(0.0,0,150,-0.3)'>- </span><span style='background-color:rgba(21.450867354869843,0,150,-0.21587895154953002)'>Hold </span><span style='background-color:rgba(1.5345374448224902,0,150,-0.2939822060987353)'>Me </span><span style='background-color:rgba(19.608353823423386,0,150,-0.22310449481010436)'>Now. </span><span style='background-color:rgba(0.0,0,150,-0.3)'>Tune </span><span style='background-color:rgba(184.1085720062256,0,150,0.4219944000244141)'>in: </span><span style='background-color:rgba(63.75339701771736,0,150,-0.04998667836189269)'>http://stream.laut.fm/eurodance.m3u\\n' </span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXAl0DScpV1B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}